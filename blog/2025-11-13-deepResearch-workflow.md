# 基于本地 LLM API 的深度研究工作流（DRW）构建蓝图：以非 SLAM 3D 追踪/导航文献综述为例

## I. 自主研究智能体的基础架构

### A. 深度研究工作流（DRW）范式的界定

传统的单体式大型语言模型（LLM）在执行多步骤、高复杂度且需长期记忆的学术研究任务时存在明显局限。单个模型同时承担规划、执行、检索和综合，往往缺乏维持状态、处理复杂决策以及精确纠错的机制。

完整的文献综述任务包含“识别论文—逐篇阅读—交叉引用—合成结论”等数十个顺序与条件步骤。要让 LLM 从文本生成器转型为可执行复杂任务的自主系统，必须赋予其智能体（Agentic）能力，使其能够适应输入、调用外部工具并自主执行预设或自适应的工作流。

在深度研究场景中，LLM 需要具备实时信息检索、任务进度管理以及失败后的自我恢复能力。因此，分层多智能体架构是 DRW 的必要条件，它模拟组织化的管理体系，将复杂任务拆解并交给专业化的子智能体，从而保证系统的专业性与鲁棒性。

分层架构的关键优势包括：

- **专业化与解耦**：避免单一智能体承担全部工作导致的效率低下与脆弱性，通过专职智能体（如 RAG 执行者）实现功能隔离。
- **控制流与维护性**：提供清晰的委托规则、退避重试（backoff retries）与故障转移逻辑。

当外部工具调用失败时，总任务智能体可以决定重试、更换工具或标记论文失败后继续下一项，从而保障系统稳定与可维护性。

### B. 本地 LLM 的必然要求：隐私、控制与成本效益

“本地搭建”是架构设计的关键约束。采用 Ollama 等本地 LLM 服务平台能够增强数据隐私，减少对第三方云服务的依赖，并完全掌控模型版本与参数，从而满足成本与安全性的双重需求。

## II. 核心编排框架的选择与实施

### A. 对比分析：为何选择 LangGraph

智能体框架大致分为两类：一类追求配置驱动的简单性（如 CrewAI），另一类提供图驱动的编排控制能力（如 LangGraph）。CrewAI 在角色分工明确的简单任务中表现良好，但面对复杂的条件执行或流程分支时缺乏灵活性。AutoGen 擅长对话式协作，却难以满足科研任务所需的高确定性。

LangGraph 基于 LangChain 原语构建运行时，其核心即状态机。对于复杂且长周期的 DRW，图结构是刚性需求，因为它能够：

- **确保确定性工作流**：明确定义节点（规划、执行、合成）与状态转换。
- **实现条件执行**：强制执行 if/then/else 逻辑，例如“RAG 失败则重试，成功则验证”。
- **支持持久状态**：原生提供状态管理与检查点，对耗时数小时甚至数天的流程至关重要。

### B. 主管—子团队分层结构

- **总任务智能体（Total Task Agent, TTA）/ 主管**：负责高层规划、任务拆解、`paper_list` 进度跟踪、状态条件路由以及最终合成。
- **委托机制**：根据用户查询与子智能体描述决定任务路由，必要时将论文检索任务委托给执行智能体。
- **研究执行智能体（Research Executor Agent, STA）**：与外部环境（Model Context Protocol, MCP 服务器）交互，负责文档检索、RAG 调用与结构化摘要生成。

### C. 共享状态架构

共享状态对象是整个工作流的“单一事实来源”，用于记录流程状态、中间结果与进度。所有智能体必须通过标准化接口读写该状态，以实现模块化解耦：

- TTA 无需了解 STA 执行 RAG 的细节，只需读取写回的结果。
- 即便替换 RAG 流程或底层工具链，也不会影响 TTA 的高层逻辑，实现可扩展的软件架构原则。

示例字段如下：

| 字段 | 类型 | 说明 | 使用方 |
| --- | --- | --- | --- |
| `query_topic` | 字符串 | 初始研究查询 | TTA（规划） |
| `paper_list` | 列表（字典） | 论文主列表：URL、标题、状态 | TTA（分配、追踪） |
| `current_paper_id` | 字符串 | 当前 STA 处理的文档 ID | TTA / STA |
| `next_task_route` | 字符串 | 下一节点条件字段 | TTA（路由） |
| `task_output` | 字符串 / 字典 | STA 产出的摘要或错误信息 | STA / TTA |
| `verified_summaries` | 字典 | 经核查的摘要索引存储 | TTA / 合成智能体 |
| `error_log` | 字符串列表 | 失败调用与幻觉警告 | TTA（回退） |
| `synthesis_draft` | 字符串 | 文献综述草稿 | TTA / 合成智能体 |

## III. 通过模型上下文协议（MCP）实现工具访问

### A. MCP 在学术研究中的作用

深度研究需要可靠、标准化的数据接口。MCP（Model Context Protocol）通过开放协议，定义了应用如何向 LLM 提供工具与上下文，确保数据摄取的一致性与可验证性。

MCP 服务器可同时暴露：

- **工具（Tools）**：执行特定任务，如网络搜索、文件解析。
- **提示（Prompts）**：针对任务的提示模板，例如“系统综述大纲提示”。
- **资源（Resources）**：提供学术论文 PDF 或文本片段作为上下文。

借助 MCP，DRW 能以统一方式连接 GitHub、Slack、Google Drive 等资源。若未来接入授权学术数据库，只需替换 MCP 服务器实现，高层编排无需变动。

### B. 构建论文检索用 MCP 服务器

STA 必须完成“通过 MCP 联网读取指定论文并总结”的职责，因此需要搭建封装 RAG 前置流程的 MCP 服务器，核心能力包括：

- `fetch_and_prepare_resource(url)`：下载 PDF 并转换成标准资源对象。
- `perform_rag_query(resource_id, question)`：对摄取后的论文执行检索增强生成。
- **传输方案**：本地可采用 `stdio`；若需并行或远程访问，可切换到支持流式的 HTTP 传输。

### C. 在 STA 中集成 MCP

STA 作为 MCP 客户端，可使用 `MultiServerMCPClient` 安全调用服务器工具。论文分析通常需要顺序推理（先“方法”，再“实验”，最后“总结”），因此 STA 需要通过 `ClientSession` 维持跨调用状态，实现类似研究员的深度迭代分析。

## IV. 子任务智能体：论文 RAG 管道

### A. 数据摄取与准备

学术论文结构复杂，RAG 的数据处理质量直接决定结果准确性：

- **复杂文档处理**：必须使用能识别章节、段落、图表的文本分割器，保障语义连贯。
- **向量存储与嵌入模型**：可采用 Pinecone 或本地 Chroma，嵌入模型由本地 Ollama 提供，构建混合式 RAG，结合生成与检索优势，降低幻觉率。

### B. 智能体式 RAG 与迭代摘要

STA 在 LangGraph 的指导下进行智能决策，仅在需要外部上下文时调用 RAG。它通过多轮定向查询（如“提取架构细节”“总结消融实验”）收集事实，再综合输出高质量摘要。

### C. 高级上下文工程与长期记忆（VCM）

LLM 的上下文窗口限制是深度研究的主要挑战。可引入受 MemGPT 启发的虚拟上下文管理（Virtual Context Management, VCM）：

- **核心记忆（Core Memory）**：相当于 RAM，存储当前指令与摘要。
- **归档上下文（Archival Context）**：相当于磁盘，存储所有已验证摘要（如向量数据库）。

VCM 在固定窗口内模拟“无限上下文”，支持跨论文事实汇总。合成智能体具备自定向检索能力，可调用工具按主题调取历史摘要，例如“检索所有提及‘非视觉里程计’的摘要”。

## V. 工作流执行、质量保障与稳健合成

### A. 委托循环与条件执行

TTA 持续监控共享状态，依次选择 `paper_list` 中的待处理论文，更新 `current_paper_id` 并路由给 STA。凭借 LangGraph 的条件路由能力，可构建稳健的错误处理：

1. **首次失败**：立即重试 MCP 调用。
2. **二次失败**：记录错误并返回 TTA 重新评估，例如改用网络摘要工具。
3. **最终失败**：将论文标记为 `Failed`，继续下一项，避免流程阻断。

### B. 数据质量：事实基础与引文校验

为最大程度降低幻觉风险，需要验证智能体对 STA 生成的摘要进行原文核查。关键指标如下：

| 指标 | 定义 | 对 DRW 的重要性 |
| --- | --- | --- |
| 正确性（Correctness） | 事实点可在引用文档中核实的比例 | 学术诚信的底线 |
| 完整性（Completeness） | 查询或文档关键要点的覆盖程度 | 确保分析全面 |
| 关联性（Relevancy） | 引用资源与生成内容的相关度 | 验证任务匹配性 |

### C. 合成智能体：整合最终输出

当所有论文分析完成或达到失败阈值，TTA 将流程路由至合成阶段。合成智能体通过 VCM 检索已验证摘要，按照标准综述结构（如非 SLAM 3D 方法分类、传感器融合对比、挑战识别）生成报告。LangGraph 的流式输出能力保证用户实时查看长文档生成过程。

### D. 人在回路（HILT）检查点

在高度自主系统中引入 HILT 至关重要。LangGraph 支持在工作流中暂停、等待用户输入并从相同状态继续。建议的人工介入点包括：

- **大纲审查**：TTA 制定初始论文列表与研究计划后，人工确认与调整。
- **合成审查**：最终报告提交前，由人工审阅草稿，确保学术质量与方向。

结合评估指标与可观察性工具（如 LangSmith），系统不仅能执行任务，还能自我改进。`error_log` 与验证得分帮助持续优化提示工程与 RAG 管道，将智能体系统视为可度量、迭代的软件产品。
