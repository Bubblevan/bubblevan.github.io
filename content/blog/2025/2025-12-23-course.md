---
date: 2025-12-23
title: 美国高校Agent、VLA与 Embodied AI 课程深度调研
authors: [bubblevan]
tags: []
---

## 1. 执行摘要

在过去十年中，美国顶级计算机科学（CS）课程体系经历了一场从"静态预测模型"向"动态智能体系统"的深刻范式转移。如果说**UC Berkeley**的**CS61B**（数据结构）和**MIT**的**6.S081**（操作系统）曾是定义上一代软件工程师能力的基石，那么以**大语言模型智能体（LLM Agents）**、**视觉-语言-动作模型（VLA）**和**具身智能（Embodied AI）**为核心的新一代课程，正在重塑当下顶级CS人才的培养标准。


调研发现，这些课程不再仅仅关注模型架构或损失函数的优化，而是转向了 **"系统级智能"**的构建。学生不仅需要训练模型，更需要构建能够感知环境、进行多步推理（**Reasoning**）、规划任务（**Planning**）、使用工具（**Tool Use**）并执行物理动作（**Action**）的完整闭环系统。

这一新兴课程体系呈现出明显的**"双轨制"**特征：

- **认知智能轨道（Cognitive Track）**：以UC Berkeley和Columbia为代表，侧重于利用**LLM**构建能够解决复杂软件任务、进行代码生成和API调用的智能体系统
- **具身智能轨道（Embodied Track）**：以Stanford、MIT和CMU为代表，侧重于**VLA模型**、**模拟到现实（Sim-to-Real）**迁移以及机器人操控的物理交互

本报告将深入剖析这些课程的教学大纲、作业设计（**Homework**）及期末项目（**Project**），揭示其如何通过高强度的工程实践，填补前沿研究与工业应用之间的鸿沟。

## 2. 课程范式的演变：从"深度学习"到"智能体系统"

传统的深度学习课程（如**Stanford CS231n**或**CS224N**）主要致力于解决从输入到输出的映射问题（例如图像分类或机器翻译）。然而，随着**GPT-4**等基础模型的出现，学术界的关注点已从"训练更好的模型"转移到"如何使用模型构建能够行动的系统"。

### 2.1 新时代的"CS61B"：构建智能系统的核心能力

在传统的CS教育中，**CS61B**等课程通过构建编译器、数据库或操作系统内核，训练学生管理复杂度的能力。在**Agent**时代，这种系统构建能力的内涵发生了变化：

- **非确定性系统的管理**：学生必须学会处理**LLM**输出的随机性，设计鲁棒的控制流（**Control Flow**）来约束智能体的行为
- **工具与环境交互**：课程作业不再是封闭的Jupyter Notebook，而是要求智能体与外部环境（如Web浏览器、机器人仿真器、代码解释器）进行实时交互
- **多模态融合**：**VLA模型**的引入打破了**CV**与**NLP**的界限，学生需要在一个统一的**Token空间**内处理视觉感知与动作控制

### 2.2 核心技术栈的重构

调研显示，这些课程的技术栈已显著区别于传统ML课程：

- **中间件层**：**LangChain**、**AutoGen**、**LlamaIndex**、**LeRobot**
- **仿真环境**：**Drake** (MIT)、**MuJoCo** (Berkeley/Stanford)、**Habitat**、**Isaac Sim**
- **数据格式**：**RLDS (Reinforcement Learning Datasets)** 用于标准化机器人数据

## 3. 认知智能轨道：UC Berkeley与Columbia的系统化探索

**UC Berkeley**和**Columbia University**在**LLM Agents**领域开设了极具代表性的课程，这些课程侧重于智能体的推理能力、规划算法以及企业级应用的可靠性。

### 3.1 UC Berkeley: CS 294/194-196 Large Language Model Agents

这门课程是目前全球范围内关于**LLM智能体**最系统、最前沿的教学尝试。由**Dawn Song**教授和**Google DeepMind**研究员**Xinyun Chen**联合讲授，该课程直接对标**Agent**领域的最新研究进展。

#### 3.1.1 课程大纲与核心议题

该课程的设计逻辑非常清晰，旨在解构智能体的认知架构：

- **推理与规划（Reasoning & Planning）**：课程深入探讨了**Chain-of-Thought (CoT)**、**Tree of Thoughts (ToT)** 以及更高级的**推理时计算（Inference-time Compute）**技术。作业可能涉及复现这些推理模式，使模型能够分解复杂问题
- **工具使用与函数调用（Tool Use & Functional Calling）**：这是**Agent**从"聊天机器人"进化为"数字员工"的关键。学生学习如何构建**ReAct（Reasoning + Acting）**循环，使模型能够自主决定何时调用搜索API或计算器
- **多智能体系统（Multi-Agent Systems）**：探讨多个**Agent**如何通过协作或辩论来提升整体性能，涉及**AutoGen**等框架的应用

#### 3.1.2 作业与项目设计（Homework & Projects）

该课程采用了独特的**双轨制项目（Split-Track Project）**，以满足不同背景学生的需求：

**应用轨道（Applications Track）**：

- **目标**：构建具有实际应用价值的**Agent**系统
- **典型选题**：类似于**SWE-bench**的"自动编程Agent"，能够自主读取GitHub Issue并提交PR；或者"法律助手Agent"，能够跨多个文档进行**检索增强生成（RAG）**并生成法律摘要
- **要求**：强调实现的完整性和对现实世界问题的解决能力，通常需要包含一个可交互的前端或API接口

**研究轨道（Research Track）**：

- **目标**：产出可发表的Workshop或会议论文
- **典型选题**：设计新的推理算法以提升数学证明能力（如**AlphaProof**相关主题）；开发针对**Agent**安全性（如**Prompt Injection**防御）的新型评测基准
- **要求**：需要有严谨的实验设计和基准对比（**Benchmarking**）

#### 3.1.3 教学资源与客座讲座

该课程极度依赖前沿讲座，邀请了来自**OpenAI**、**Anthropic**、**DeepMind**的核心研究员（如**Denny Zhou**、**Jason Weston**）。这意味着学生的"阅读材料"往往是上周才发表在**arXiv**上的论文。这种教学模式要求学生具备极强的自学能力和文献综述能力，能够迅速将前沿理论转化为代码实现。

### 3.2 Columbia University: COMS 6113 Agentic Systems Made Real

如果说Berkeley的课程关注"算法创新"，**Columbia**的**COMS 6113**则更像是一门"系统工程"课。它关注的是如何将脆弱的**Agent**构建为可靠的企业级系统。

#### 3.2.1 硬边界与软边界任务

课程提出了一个核心概念区分：

- **软边界任务（Soft-edge tasks）**（如创意写作，容错率高）
- **硬边界任务（Hard-edge tasks）**（如医疗诊断、金融交易，容错率极低）

课程的**Project**重点在于如何让**Agent**在硬边界任务中表现出高可靠性。

#### 3.2.2 基础设施视角

作业和项目要求学生思考支持**Agent**运行的底层系统：

- **数据系统**：传统的数据库如何适应**Agent**的记忆存储（**Vector DB**）？如何管理**Agent**的长期记忆？
- **人机交互（HCI）**：当人类与一个拥有自主行动权的**Agent**交互时，界面和交互逻辑应如何设计以确保安全？
- **规模化（Scaling）**：当**Agent**数量增加100倍时，系统负载和API成本如何优化？

#### 3.2.3 研讨会式的项目驱动

这门课采用了高强度的研讨会形式，学生被要求作为"共同研究者"（**Co-investigators**）参与。期末项目占总成绩的**40%**，要求提交一篇符合会议标准的论文（**30%**）和进行现场展示（**10%**）。项目建议书需要经过严格的审查，确保选题具有足够的研究深度。

## 4. 具身智能轨道：Stanford与MIT的物理交互

在具身智能领域，重点从软件API转向了物理世界的感知与控制。**Stanford**和**MIT**代表了两种不同的流派：前者倾向于利用大模型（**VLA**）实现端到端控制，后者则坚持**基于物理模型（Model-based）**的严谨控制理论与学习方法的结合。

### 4.1 Stanford University: VLA与机器人的融合

Stanford的课程体系非常敏锐地捕捉到了**Transformer**架构在机器人领域的爆发。

#### 4.1.1 CS 224R: Deep Reinforcement Learning

这门课虽然名为"深度强化学习"，但近年来内容已大幅向**机器人学习（Robot Learning）**和**VLA**倾斜。它是**CS224**系列（NLP）和**CS231**系列（CV）在动作领域的自然延伸。

**VLA核心项目（The VLA Project Ecosystem）**：

调研发现，该课程的**Final Project**经常涉及对**OpenVLA**、**RT-2**或**ACT (Action Chunking with Transformers)** 等模型的微调与应用：

- **典型作业**：学生需要处理包含图像、语言指令和机器人动作（**Joint positions/velocities**）的多模态数据集（如**BridgeData V2**）
- **微调实战**：使用**LoRA (Low-Rank Adaptation)** 技术在消费级GPU上微调**7B**参数量的**VLA模型**，使其适应新的物体抓取任务或指令
- **动作解码**：理解如何将**VLA**输出的离散**Token**解码为连续的机器人控制信号。这要求学生深入理解**Tokenizer**的工作原理以及如何将物理空间离散化

**Sim-to-Real迁移挑战**：

许多项目聚焦于在仿真环境（如**MuJoCo**）中训练策略，然后尝试将其迁移到真实机器人（或更逼真的仿真设置）中。这涉及到**领域随机化（Domain Randomization）**技术的应用，即在训练中随机改变光照、摩擦力、物体纹理，迫使**Agent**学习到鲁棒的特征。

#### 4.1.2 CS 25: Transformers United

这门研讨课虽然只有**1学分**，但却是了解**VLA**前沿的风向标。课程专门设有"**Robotics and RL**"模块，邀请**NVIDIA (Project GR00T)** 和**Google DeepMind (RT系列)** 的研究员讲解**Transformer**如何统一机器人控制。对于希望在**Project**中做**VLA**相关题目的学生，这门课提供了必要的理论图谱。

### 4.2 MIT: 6.4210/6.4212 Robotic Manipulation

**MIT**的这门课程是机器人操控领域的"硬核"标杆，由**Russ Tedrake**教授主讲。与Stanford侧重端到端学习不同，**MIT**更强调**基于模型的控制（Model-based Control）**与学习方法的结合。

#### 4.2.1 Drake生态与Deepnote作业

课程完全基于**MIT**开发的**Drake**仿真与控制库。这不仅是一个模拟器，更是一个基于物理的优化工具箱。

**Deepnote作业平台**：所有的作业都通过**Deepnote**（一种云端Jupyter环境）分发。这意味着学生不需要本地配置复杂的C++环境，可以直接在浏览器中进行高强度的物理仿真。

**作业深度解析**：

- **运动规划（Motion Planning）**：学生需要手写实现**RRT\***或基于轨迹优化的规划算法，而不仅仅是调用库
- **抓取规划（Grasp Planning）**：基于点云数据（**Point Clouds**）计算抓取姿态，涉及反向运动学（**IK**）的求解
- **力控与动力学**：理解并在代码中实现**阻抗控制（Impedance Control）**，这对于处理接触任务（如擦桌子、插孔）至关重要
- **全栈系统构建**：课程的终极目标是让学生构建一个完整的软件栈。不同于ML课程只关注**Policy Network**，这里关注的是**Perception -> Planning -> Control**的完整管线

## 5. CMU与Robot Learning：实验主义的摇篮

**Carnegie Mellon University (CMU)** 的**Robotics Institute**是全球机器人研究的重镇，其课程体系极具实验色彩，强调算法在真实数据上的表现。

### 5.1 16-831: Introduction to Robot Learning

这门课被视为**CMU**在具身智能领域的入门必修课，直接对标**Berkeley**的**CS 285**，但更偏向机器人应用。

#### 5.1.1 课程三支柱

课程内容围绕三个核心支柱展开：

- **模仿学习（Imitation Learning）**：深入讲解**Behavior Cloning (BC)**、**DAgger (Dataset Aggregation)** 和**Inverse RL**。这是目前训练机器人最有效的方法之一，作业通常要求学生从专家演示数据中克隆策略
- **强化学习（Reinforcement Learning）**：涵盖**Model-free (PPO, SAC)** 和**Model-based (PETS, Dreamer)** 方法
- **Sim-to-Real技术**：专门的模块讲解如何弥合仿真与现实的差距，这是工业界最看重的技能之一

#### 5.1.2 典型的Homework与Project

**作业形式**：结合了理论推导与代码实现。代码作业通常基于**OpenAI Gym**或**PyBullet**环境，要求学生从零实现算法（如**DDPG**或**SAC**）并控制一个多自由度的机械臂或移动机器人。

**期末项目**：鼓励探索开放性问题，如"基于视觉的灵巧手操作"或"多机器人协作导航"。由于**CMU**拥有强大的硬件资源，部分项目甚至允许在真实机器人上进行验证。

## 6. 作业类型学分析：这一代学生在写什么代码？

综合以上高校的课程调研，我们可以将当前的**Agent/VLA/Embodied**作业归纳为三种核心范式。这三种范式代表了当前CS教育对"智能系统构建能力"的具体定义。

| 作业范式 | 典型课程 | 核心任务描述 | 涉及技术栈 | 教育目标 |
|---------|---------|------------|-----------|---------|
| Cognitive Agent Loop (认知循环) | Berkeley CS294, Columbia COMS 6113 | 构建一个能够自主分解用户指令、调用外部工具（搜索、计算、代码执行）、并根据反馈修正计划的软件Agent | LangChain, AutoGen, OpenAI API, Vector DB | 掌握LLM的推理能力、ReAct模式、长上下文管理 |
| VLA Fine-Tuning (端到端VLA) | Stanford CS224R, Open Source Tutorials | 处理机器人演示数据（RLDS格式），微调多模态大模型（如OpenVLA），实现从像素到动作的端到端控制 | PyTorch, LoRA, Hugging Face, RLDS | 理解多模态Token化、动作空间的离散化、大模型微调技术 |
| Sim-to-Real Control (虚实迁移) | MIT 6.4210, CMU 16-831 | 在高保真物理仿真中训练策略（通过RL或优化方法），并通过域随机化技术使其具备鲁棒性，应对环境扰动 | Drake, MuJoCo, Isaac Sim, PPO/SAC算法 | 掌握刚体动力学、最优控制、鲁棒性设计 |

### 6.1 深度解析：构建一个ReAct Agent（Berkeley风格）

在这类作业中，学生不再是编写一个死板的脚本，而是编写一个**Prompt模版**和一个解析器。

- **Prompt设计**：`"You are a helpful assistant. You have access to the following tools:. To use a tool, please output: Action: ToolName(Args)..."`
- **解析循环**：学生需要编写Python代码来正则匹配**LLM**的输出，截获**Action**指令，执行对应的Python函数，然后将函数返回值封装成`"Observation:..."`再次喂给**LLM**
- **挑战点**：如何处理**LLM**的幻觉（**Hallucination**）？如果**LLM**调用了一个不存在的函数怎么办？作业往往要求实现错误处理机制，让**Agent**能够"自我纠错"

### 6.2 深度解析：Sim-to-Real的挑战（MIT/CMU风格）

这类作业的核心在于对抗性思维。

- **任务**：训练一个机械臂将方块推到目标点
- **陷阱**：在测试时，方块的质量会变，桌面的摩擦系数会变，摄像头的角度会有噪声
- **解决方案**：学生必须在训练循环中引入**DomainRandomization**，例如 `friction = uniform(0.5, 1.0)`
- **学生需要可视化训练曲线**，观察随着随机化程度增加，策略的收敛难度如何上升，但泛化能力如何增强。这模拟了真实的机器人开发流程。

## 7. 民主化与开源：走出象牙塔的Agent教育

除了顶尖高校的正式课程，调研还发现开源社区和竞赛正在承担起普及**Agent**和**VLA**技术的重任。这些资源往往提供更贴近工业界实战的"作业"。

### 7.1 Hugging Face与LeRobot

**Hugging Face**推出的**Agents Course**和**Robotics Course**在内容深度上已不输高校选修课。

- **Agents Course**：涵盖了**smolagents**、**LangGraph**等最新框架。期末作业是提交一个**Agent**到排行榜（**Leaderboard**）上与其他人的**Agent**进行PK，这种竞技性极大地激发了学习热情
- **LeRobot项目**：这是一个旨在通过开源软硬件降低机器人学习门槛的项目。它提供了低成本机械臂（**SO-100**）的组装指南和配套的训练代码（基于**PyTorch**）。这使得没有百万美元实验室的学生也能在家完成"**Sim-to-Real**"的闭环

### 7.2 竞赛即项目

见[隔壁比赛调研](./2025-12-23-competition.md)。

## 8. 结论与展望

美国CS课程在**Agent**、**VLA**和**Embodied AI**领域的演进，清晰地表明了计算机科学教育正在经历一次**"从代码到认知"**的跃迁。

- **系统复杂度的提升**：现在的"Hello World"不再是打印一行字，而是让一个**Agent**成功调用一次API。现在的"编译器大作业"不再是写一个C编译器，而是微调一个**7B**的**VLA模型**并让它控制机械臂抓起一个苹果
- **双轨并行的趋势**：想要深入这一领域的学生或研究者，需要同时关注**Berkeley/Columbia**的软件智能体架构（如何思考）和**Stanford/MIT/CMU**的具身控制理论（如何行动）。未来的顶级工程师将是这两条轨道的集大成者
- **开源生态的驱动**：随着**LeRobot**、**OpenVLA**等开源项目的成熟，高质量的**Agent**教育正在从斯坦福的实验室流向**GitHub**和**Hugging Face**

对于正在调研或设计相关课程的教育者而言，参考**CS 294**的**Guest Lecture**模式（保持前沿）、**CS 224R**的**VLA微调**项目（拥抱大模型）以及**MIT 6.4210**的仿真全栈实践（不忘物理根本），是构建具有世界级竞争力的**Agent**课程的关键路径。

## 附录：核心课程资源索引表

| 学校 | 课程编号 | 课程名称 | 核心领域 | 关键作业/项目类型 |
|------|---------|---------|---------|----------------|
| UC Berkeley | CS 294/194-196 | Large Language Model Agents | Cognitive Agents | ReAct Loop, Tool Use, Multi-agent, RAG |
| Stanford | CS 224R | Deep Reinforcement Learning | Embodied VLA | OpenVLA Fine-tuning, Sim-to-Real, PPO for Robotics |
| MIT | 6.4210 | Robotic Manipulation | Physical Control | Drake Simulation, Motion Planning, Force Control | 
| CMU | 16-831 | Intro to Robot Learning | Robot Learning | Imitation Learning, RL from Scratch, Visual Learning |
| Columbia | COMS 6113 | Agentic Systems Made Real | Enterprise Systems | Agent Reliability, Scaling, System Architecture |
| Hugging Face | Online | Agents Course | Practical Dev | Leaderboard Competition, LangGraph, Evaluation |
| Hugging Face | Online | Robotics Course | Open Hardware | LeRobot Stack, SO-100 Arm Control |
| MIT | 6.S184 | Flow Matching and Diffusion Models | Generative Models | Flow Matching, Diffusion Models, Score-based Models |
| Stanford | CS336 | Language Modeling from Scratch | LLM Fundamentals | From Scratch Transformer, Training Pipeline, Optimization |
| UC Berkeley | CS 285 | Deep Reinforcement Learning | Robot Learning | RL Algorithms, Imitation Learning, Policy Gradients |