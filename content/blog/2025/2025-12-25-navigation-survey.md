---
date: 2025-12-25
title: What is Navigation？
authors: [bubblevan]
tags: []
---

## 1. 导航任务分类体系

从高到低，导航任务可以分为底层基础和高层复合两类任务。

### 1.1 底层基础任务

底层基础任务具有三个核心特征：首先，它们针对单一明确目标（点、物体、位置或人），目标定义清晰且直接；其次，每个任务都拥有相对独立的感知-决策-执行链路，可以单独完成而不依赖其他任务；最后，这些任务构成了具身导航能力的"原子"单元，是构建更复杂导航系统的基础组件。

| 任务类型 | 定义 | 特点 | 典型应用 |
|---------|------|------|---------|
| **PointNav（点导航）** | 智能体导航至环境中指定的几何坐标点（不考虑语义） | 仅关注空间位置，不涉及目标物体识别，地图主要编码几何信息 | 机器人从 A 点到 B 点的路径规划，不考虑沿途物体 |
| **ObjectNav（物体导航）** | 智能体导航至特定类别物体（如 "找椅子"）或特定实例物体（如 "找我的咖啡杯"）的位置 | 需要物体识别能力，地图整合了语义信息 | 家庭服务机器人寻找特定物品，工业质检机器人定位缺陷 |
| **LocationNav（位置导航）** | 智能体导航至具有语义标签的位置（如 "厨房"、"客厅"） | 关注环境的功能区域，而非具体物体或几何点 | 老人辅助机器人导航至卫生间，医院导诊机器人引导至挂号处 |
| **HumanFollowing（人类跟随）** | 智能体持续跟踪并跟随人类目标（可保持固定距离或相对位置） | 需要实时人体检测、轨迹预测和动态避障能力 | 行李搬运机器人跟随旅客，导购机器人陪同顾客 |
| **Embodied Question Answering (EQA)（具身问答）** | 智能体在探索环境过程中回答关于环境的问题 | 融合导航与问答能力，需要理解空间关系和语义信息 | 博物馆导览机器人回答 "蒙娜丽莎在哪里"，智能家居助手回答 "遥控器在哪个房间" |
| **Visual-Audio Navigation (VAN)（视听导航）** | 智能体利用视觉和听觉信息导航至发出特定声音的目标 | 多模态感知融合，适用于视觉受限或需要声音定位的场景 | 搜救机器人定位求救声源，智能音箱 "听到" 呼唤后移动 |

![底层基础任务示意图](/images/social-nav/basic-navigation-tasks.png)

> 现代具身导航研究正趋向任务统一，如 Uni-NaVid 等模型试图将多种基础任务（包括 PointNav、ObjectNav、VLN、EQA 和 HumanFollowing）整合到一个框架中，但这并不改变它们在分类学上的层级关系

### 1.2 高级复合任务

高级复合任务与底层基础任务形成鲜明对比。这些任务的目标通常由语言描述而非直接指定，需要智能体进行多级推理和任务分解。它们本质上是由多个基础导航任务组合而成的"任务流"，而非单一任务类型。这种复合性质使得高级任务能够处理更复杂、更贴近真实应用场景的导航需求。

| 任务类型 | 定义 | 核心特点 | 基础任务依赖 | 典型场景 |
|---------|------|---------|------------|---------|
| **多指令连续导航（Sequential Language-guided Navigation, SLN）** | 根据多轮 / 连续自然语言指令完成串联导航任务（如 "先去客厅茶几拿遥控器，再去阳台浇花，最后回到卧室充电"） | 需要任务分解、顺序执行、中途状态保存，本质是「VLN + 多任务规划」的复合 | ObjectNav（拿遥控器）+ PointNav（浇花 / 充电位置）+ 任务优先级排序 | 家庭服务机器人执行多步骤指令、酒店机器人完成客房配送全流程 |
| **协作式导航（Collaborative Navigation）** | 多智能体（机器人 / 人类）协作完成单智能体无法实现的导航任务（如大型仓库中，一个机器人探路标记障碍，另一个机器人运输货物） | 需要智能体间通信、任务分配、全局目标对齐，本质是「基础导航 + 多智能体协同」 | PointNav（路径规划）+ 环境感知共享 + 动态角色调整 | 搜救机器人编队探索废墟、工厂多机器人协同搬运 |
| **动态目标导航（Dynamic Target Navigation）** | 导航至移动中的目标（如走动的人、被搬运的物体、临时移动的障碍物），而非静态目标 | 需要实时目标追踪、轨迹预测、动态路径重规划，本质是「HumanFollowing + PointNav」的升级 | HumanFollowing（目标追踪）+ PointNav（实时路径更新） | 餐厅机器人追着服务员送餐具、机场机器人导航到移动的旅客 |
| **多模态指令导航（Multimodal Instruction Navigation）** | 基于图像、语音、文字、手势等多模态指令的导航（如用户发一张照片说 "去这个地方"，或指着方向说 "往那边走"） | 比 VLN 更复杂（VLN 仅纯语言），需要跨模态信息融合、指令意图统一解析 | 视觉理解（图像 / 手势识别）+ 语音识别 + PointNav/ObjectNav | 盲人辅助机器人根据用户语音 + 手势导航、导游机器人根据游客照片找到对应景点 |
| **约束条件导航（Constrained Navigation）** | 满足特定约束（安全 / 效率 / 偏好）的导航（如 "避开红色物体"、"最短时间到达"、"能耗最低"、"不打扰行人"） | 需要约束建模、多目标优化，本质是「基础导航 + 约束决策」 | PointNav（路径规划）+ 约束优先级排序（如安全 > 效率） | 医院机器人导航时避开病人、无人机在禁飞区边缘规划路径 |
| **人机交互协同导航（Human-Robot Interactive Navigation, HRIN）** | 人类实时交互调整导航目标 / 策略（如用户中途说 "不去厨房了，去卧室"，或机器人询问 "前方拥堵，是否绕行？"） | 需要实时意图理解、动态任务重规划、交互式决策，本质是「VLN + 实时人机反馈」 | VLN（指令解析）+ 动态路径重规划 | 导购机器人根据用户实时需求调整导航目的地、家庭机器人响应临时指令变更 |
| **应急响应导航（Emergency Response Navigation）** | 紧急场景下的导航（如火灾时找逃生通道、地震后搜救幸存者），需优先满足安全 / 生存约束 | 需要环境风险评估、快速决策、容错机制，本质是「基础导航 + 应急决策」 | PointNav（路径规划）+ 危险区域识别（如高温 / 坍塌区） | 消防机器人在火场中导航到被困人员位置、地震救援机器人穿越废墟 |

所有高级复合导航任务都遵循两个共同特征：首先，它们以 PointNav 或 ObjectNav 等基础导航任务为执行核心，确保基本的空间移动能力；其次，它们叠加至少一种额外能力，如语言理解、多智能体协作、动态规划或约束优化等。值得注意的是，VLN（视觉语言导航）和 DDN（需求驱动导航）只是其中最常见的两类，前者叠加单轮语言理解，后者叠加需求推理能力。

![高级复合任务架构图](images/social-nav/composite-navigation-tasks.png)

### 1.3 Social Navigation

社交导航（Social Navigation）是一个特殊的复合导航任务，它由两个层次构成。**基础执行层**依赖 PointNav（路径规划到目标点）或 ObjectNav（导航到目标物体）的核心能力，完成空间移动的基础需求。**复合能力层**则必须满足社交维度的约束，这使其区别于普通的"物理避障导航"。

在复合能力层中，社交导航需要遵循人类社交规则，例如不横穿正在对话的人群、保持 1.2-1.5 米的社交距离、优先礼让行人等。同时，它还需要理解人类行为意图，如识别行人的行走方向、判断是否需要等待他人通过。此外，社交导航必须适配不同社交场景，例如医院需要安静缓慢导航，而商场则需要高效避让但不干扰购物。

与普通导航的本质区别在于：普通导航只解决"不撞墙、不碰物体"的物理约束，而社交导航还要解决"不冒犯人类、符合社交礼仪"的社交约束。从分类学角度看，社交导航属于之前提到的「约束条件导航」的细分专项，其约束维度聚焦于"社交规则"。然而，由于社交约束的复杂性和独特性（涉及人类行为预测、场景化社交规则），它往往被单独研究和讨论。

![社交导航双层架构图](/images/social-nav/social-navigation-architecture.png)

> 还可根据环境类型（室内 / 室外）、移动方式（轮式 / 足式 / 飞行）或感知模态（视觉 / 听觉 / 触觉）进一步划分，但这些属于次级分类维度

## 2. Habitat-sim/Habitat-Lab 仿真平台

### 2.1 Habitat PointNav 物理模拟特性

在 Habitat 框架下，PointNav (Point-Goal Navigation) 的物理模拟并非真空中的理想运动，它由以下四个核心要素构成。

**智能体建模 (Agent Modeling)**：在仿真中，智能体通常被抽象为一个具有特定半径和高度的圆柱体 (Cylinder)。它拥有物理碰撞箱，这意味着它不能穿过 NavMesh（导航网格）以外的区域或静态物体。

**动作空间与运动学 (Locomotion & Action Space)**：传统的 PointNav 采用离散动作模式，使用固定步长（如前进 0.25m）和旋转角度（如左转 10°），这种模式不涉及复杂的动力学，仅是坐标的瞬间位移与碰撞检测。而在 Habitat 2.0+ 中，系统支持基于速度控制（Velocity Control）的连续动作物理模拟，引入了摩擦力、质量和阻尼，允许智能体与环境物体发生力学交互（如推开椅子）。

**感知系统 (Sensory System)**：提供本体感受（GPS+Compass）和外感知（RGB-D、语义分割图）。在物理层面上，传感器具有遮挡特性 (Occlusion)，即智能体无法穿透墙壁看到目标，这模拟了真实世界中的视觉限制。

![Habitat 示意图](/img/social-nav/habitat-platform.png)

**环境约束 (Environment Constraints)**：基于现实扫描数据集（如 Matterport3D、Gibson），物理引擎（如 Bullet）负责实时的碰撞计算。导航限制在 NavMesh 之内，确保智能体始终位于可行走的平面上。

### 2.2 Habitat-Lab/Sim 在 ObjectNav 中的物理模拟特性

与 PointNav 相比，ObjectNav（目标驱动导航）在物理模拟上增加了语义维度和交互深度。

**语义感知系统 (Semantic Sensing)**：除了 RGB-D，ObjectNav 必须调用 SemanticSensor。在模拟层，这意味着每个 3D 网格（Mesh）都被赋予了 ID 和类别标签（如 Chair: 5）。物理模拟器不仅计算几何碰撞，还负责渲染语义地图。

**多目标成功准则 (Success Criterion)**：在 PointNav 中，物理上接近一个坐标点即成功；但在 ObjectNav 中，物理模拟器需判断智能体是否在物体 $d$ 距离内（通常为 1.0m），且该物体必须在智能体的视锥（View Cone）内，甚至需要满足特定的仰角条件。

**静态障碍物与场景复杂度**：ObjectNav 的物理环境通常比 PointNav 更"拥挤"。Habitat 使用 Bullet Physics 引擎处理复杂的室内碰撞。不同于 PointNav 常用的空旷路径，ObjectNav 涉及大量家具边缘的摩擦与遮挡模拟。

**不可达性逻辑**：由于目标是"类别"而非"点"，物理模拟器必须处理"不可见目标"或"封闭空间目标"的情况。NavMesh 在此时的作用不仅是限制行走，还要参与计算物体表面的可观察点（View Points）。

## 3. 社交导航发展历程

### 3.1 Milestone 0：社交导航的早期探索

社交导航的发展历程可以大致分为三个阶段。

**初期：规则驱动的避障（A* / ORCA）**

在早期阶段，研究者主要依赖规则驱动的方法。A* 算法作为经典的路径规划方法，通常假设环境是静态的，或者将人视为普通障碍物。ORCA（Optimal Reciprocal Collision Avoidance）基于速度障碍法的相互避让，虽然能动态调整，但往往假设对方也会配合避让，且容易在复杂环境下失效。

**中期：强化学习（RL）+ 现状感知**

随着深度强化学习的发展，这类方法开始在 PointNav 的基础上加入人作为动态元素。例如 Proximity-Aware 方法，它会通过辅助任务感知行人的距离和方向，但依然属于"近视眼"，无法应对交叉路口这种需要预判的场景。

**近期：层级化与端到端预测**

为了解决 RL "短视"的问题，开始出现结合全局规划器和低级 RL 策略的方法。这种层级化设计使得系统既能进行长期规划，又能进行实时反应。

### 3.2 Milestone 1：Falcon 的突破

Falcon 的核心创新在于将"认知（Cognition）"提升到了"预知（Precognition）"的高度，并且引入了首个真实的社交导航基准测试 (Benchmark)。这一突破标志着社交导航从被动反应转向主动预测的重要转变。

![Falcon 架构图](/paper/falcon-overview.png)

然而，结合 Falcon 的里程碑意义，目前的社交导航仍面临以下四个维度的深度挑战。

**A. 预知的局限：从"轨迹预测"到"意图博弈"**

Falcon 虽然通过预测人类轨迹并引入 Social Cognition Penalty (SCP) 解决了"避让"问题，但它尚未完全解决博弈关系。现实中人与人、人与机器是会相互影响的。当前的模拟往往把人当做"会动的圆柱体"（即使有轨迹预测），但缺乏机器动作对人心理影响的建模。例如，机器人突然加速可能导致行人受惊停步，这种心理层面的交互尚未被充分建模。

**B. 视角残缺与遮挡 (Occlusion Handling)**

这是 Falcon 论文中明确提到的漏洞：受限于 RGB-D 的视角，机器人容易在转角处与行人发生"开门杀"。社交导航不仅需要看得到的预知，更需要对视觉死角处的潜在危险进行概率性建模（Hallucination/Occultation Management）。

**C. 社交规范的"非结构化"定义**

社交礼仪（Social Norms）在不同文化和场景下是动态变化的。在 Habitat 中，我们用 Proximity Penalty (2米原则) 来定义，但在狭窄走廊里，2米是不可能的。如何实现上下文相关的社交弹性 (Context-aware Social Compliance) 是目前的短板。

**D. 长期语义与拓扑认知的缺失**

现有的 SocialNav 多数是反应性的（Reactive）。真正的"社交大拿"机器人应该能识别出："这是一群人在排队，我不应该横穿"，而不是仅仅检测到有几个圆柱体挡住了路。

但是回到这里，我们不得不重新审视一下整个领域，那就是为什么明明存在痛点 D，Falcon 及一直以来的 SocialNav 工作却一直都是基于 PointGoal Navigation 而不是语义更加丰富的 Object Navigation 呢？

### 3.3 为什么总是 PointNav？

这个问题的答案可以从五个维度来理解。

#### 任务解耦（Task Decoupling）

PointNav 关注的是"如何从 A 移动到 B"，即基本的路径规划和动态避障能力。而 ObjectNav 关注的是"哪里是 B"，即目标搜索和语义理解。Falcon 的核心创新在于"Precognition（预知）"，它想解决的是在人流密集的复杂动态环境中如何优雅、安全地穿行。如果引入 ObjectNav，会将"寻找目标物"的失败率（如模型没认出沙发）和"社交规避"的失败率混在一起，不利于验证其"未来轨迹预测"模块的有效性。PointNav 提供了确定的几何坐标点，确保了所有的失败都能回溯到社交博弈本身。

#### 几何 vs 语义（Geometry vs Semantics）

社交导航最基础的挑战是时空冲突（Spatio-temporal conflicts），即不撞到未来会出现在某处的人。这本质上是一个几何和动态预测问题。ObjectNav 更多涉及语义映射。Falcon 认为，即便目标只是一个坐标点，如果不能处理好动态行人的避让，机器人也无法在现实世界生存。

#### 计算复杂度与实时性

ObjectNav 通常需要维护一个语义地图（Semantic Map），计算开销较大。Falcon 强调的是在第一人称视图（RGBD）下的端到端快速推断，追求的是像人类一样本能地闪避行人。其需要运行复杂的 Human Trajectory Prediction (HTP) 模块和 Social Cognition Penalty (SCP) 计算，而 ObjectNav 需要额外的语义分割模型和长程记忆管理。

#### 数据集与 Baseline 的对齐

社会导航的早期基座（如 Social-Nav 任务集）大多建立在 Gibson 或 Matterport3D 的 PointNav 任务之上。为了能与前人工作（如 CrowdNav, Social-GAN）直接进行性能对比，Falcon 必须沿用同样的任务定义。

#### 评估指标的纯粹性 (SPL vs. Social Cost)

SocialNav 最核心的指标是 SPL (Success weighted by Path Length) 和 Social Violation Rate。在 PointNav 中，最短路径（Geodesic distance）是极其明确的常数。而在 ObjectNav 中，最短路径是动态且模糊的（因为可能有多个椅子）。使用 PointNav 可以更精准地衡量"为了避让行人，机器人多走了多少冤枉路"。

### 3.4 Milestone 2.1：基于 PointNav 的后续工作

在 Falcon 之后，基于 PointNav 的社交导航研究继续发展，涌现出一批重要的后续工作。

**PER-Falcon**：在 Falcon 基础上的改进，进一步优化了轨迹预测和社交认知惩罚机制。

**Risk Perception**：引入了风险感知机制，使机器人能够评估不同路径的社会风险，从而做出更合理的导航决策。

**SocialNav-Map**：构建了专门的社交导航地图，将社交规则编码到地图表示中，为导航决策提供更丰富的上下文信息。

### 3.5 Milestone 2.2：Socially-Aware Navigation (SAN) 的演进

#### 3.5.1 经典里程碑：Social Forces 与 Social LSTM

**Social Forces Model (SFM, 1995)**：社交导航的鼻祖，将人与人的交互模拟为斥力。这一模型奠定了社交导航的基础理论框架，为后续研究提供了重要的理论支撑。

**Social LSTM (CVPR 2016)**：第一次将深度学习引入轨迹预测，通过"社交池化层（Social Pooling）"让机器人开始理解人与人之间的空间关联。这一工作标志着社交导航从基于规则的方法向基于学习的方法的重要转变。

#### 3.5.2 理解"群体社交行为"的工作 (Social Grouping & Norms)

**DeepSOG (2020/2021)**：专门研究机器人如何识别"社交群体"。例如，两个人站在一起说话时，机器人不应该从他们中间穿过（即使中间有空隙），而应该绕行。这一工作强调了社交群体识别在导航中的重要性。

**Social-SAGE (2023)**：利用图卷积网络（GCN）来建模环境中人与人、人与物之间的社会关系。通过图结构表示，系统能够更好地理解复杂的社会交互模式。

#### 3.5.3 语义与 VLM 驱动的新趋势 (The "VLM/LLM" Era)

这是目前最前沿的方向，机器人开始通过自然语言理解复杂的社会规则。

**ESC (Expected Satiety Criterion, 2023/2024)**：这类研究开始讨论机器人如何通过常识推理（Reasoning）来决定导航行为。例如：看到一群人在排队，即便排队线旁边有空地，机器人也知道不应该插队。这种常识推理能力使得机器人能够做出更符合人类期望的导航决策。

**Social-Robot-VLM (2024)**：将视觉语言模型嵌入导航决策。核心逻辑是：不再仅仅是输出轨迹坐标，而是通过 LLM 解析环境——"前方有两位老人在缓慢行走，我应该从左侧宽阔区域低速绕行，且不要发出巨大的机械噪音惊吓到他们。"这种方法使得导航决策更加智能和人性化。

**SayNav (2024)**：结合了 LLM 的规划能力和 PointNav 的执行能力。虽然它主要针对 ObjectNav，但其框架完全可以扩展到社交场景，利用 LLM 的常识库来解读"什么是不礼貌的行为"。这代表了导航系统向更高层次理解发展的重要趋势。

#### 3.5.4 专门针对特定社会场景的工作

**Queuing Behavior**：有专门的研究针对"机器人自动加入排队序列"。这种场景化的研究使得机器人能够在特定社会环境中表现出更符合规范的行为。

**Intention-Aware Navigation**：不仅仅预测轨迹，还预测行人的意图（比如这个人是想去饮水机还是想去出口），代表作如 CADRL 系列的后续改进版。通过意图预测，机器人可以做出更具前瞻性的导航决策。


