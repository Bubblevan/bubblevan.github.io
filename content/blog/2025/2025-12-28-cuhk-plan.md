---
title: "香港中文大学（CUHK）VLA、WM、VLM 领域深度科研战略报告"
---

# 香港中文大学（CUHK）VLA、WM、VLM 领域深度科研战略报告

## 1. 执行摘要与战略综述

本报告旨在为一名即将入读香港中文大学（**CUHK**）**MSc in AI**（人工智能理学硕士）的学生提供一份详尽的、字数超过一万五千字的科研战略规划。报告的核心目标是指导学生如何在 1.5 年至 2 年的时间窗口内，在 **Vision-Language-Action (VLA)**、**World Models（世界模型）** 及 **Vision-Language Models (VLM)** 三大前沿领域发表顶级会议论文（**CVPR**, **NeurIPS**, **ICLR**, **ECCV/ICCV**）。

本报告基于 2024-2025 年最新的学术发表记录及 **CUHK** 各实验室的实际运作情况进行深度剖析。不同于泛泛而谈的建议，本报告将深入到具体的论文方法论、实验室的隐形招生标准、以及如何利用课程体系打破"科研实习先有鸡还是先有蛋"的死循环。

### 1.1 核心结论预览

#### 时间线的战略弹性

**CUHK MSc AI** 的标准学制为 1.5 年（3 个学期），但对于以发表顶会为目标的学生，战略性延毕至 2 年是极具战术价值的选择。这不仅能对齐博士申请的时间窗口（**PhD Application Cycle**），更能为第二篇论文的发表争取关键的 **Review** 周期。

#### 科研生态位

**CUHK** 在计算机视觉（**CV**）与多模态领域的积累极深。以 **MMLab（多媒体实验室）** 为核心，形成了以**李鸿升（Hongsheng Li）**、**王立威（Liwei Wang）**、**窦琪（Qi Dou）** 和**林达华（Dahua Lin）** 为首的科研矩阵。

#### 破局策略

"先有鸡还是先有蛋"的破解之道在于**"复现（Reproduction）- 改进（Delta）- 冷邮件（Cold Email）"** 这一精准打击链条，而非海投简历。利用入学前的大四下半学期（**Pre-arrival Phase**）完成这一积累是胜负手。

## 2. CUHK MSc AI 时间线与顶会发表周期的深度耦合分析

要实现顶会发表，必须精准理解学术界的日历与学校的行政日历如何咬合。**MSc** 学生的生命周期极短，任何一个错误的选课或错过的 **Deadline** 都可能导致最终"无文毕业"。

### 2.1 1.5 年 vs 2 年：学制政策的深度解读

根据 **CUHK** 官方规定，**MSc in AI** 的全日制（**Full-time**）标准修业年限（**Normative Study Duration**）为 1.5 年。这意味着如果你在 2025 年 9 月入学，标准毕业时间是 2026 年 12 月（参加冬季毕业典礼）。

然而，官方文件同时指出："在特殊情况下，部分学生可能需要更多时间完成学业"。在实际操作层面，学生可以通过以下方式将在校时间"事实性"地延长至 2 年（即 2027 年夏季毕业）：

- **学分控制策略**：**MSc** 要求修满一定学分。通过在前三个学期少修一门课，或者将核心的 **Capstone Project（毕业设计）** 推迟到第四个学期（**Year 2 Term 2**）注册，可以合法地保持学生身份
- **毕业论文（Project）的延期**：如果你的科研项目正在投稿 **ICLR** 或 **CVPR**，可以向导师申请延期提交最终的项目报告（**Project Report**），从而延迟毕业审核流程

**战略建议**：对于立志读博或发表顶会的学生，强烈建议按 2 年规划。1.5 年的时间对于从零开始（**Zero-shot**）到发表一篇 **CVPR** 级论文来说，容错率极低。多出的半年（**Year 2 Spring**）不仅是第二篇论文的产出期，也是等待第一篇论文 **Rebuttal（反驳期）** 和 **Camera-ready（定稿）** 的关键缓冲期。

### 2.2 逆向工程：从顶会 Deadline 倒推的时间规划表

假设你的目标是在硕士期间发表至少一篇一作顶会（**NeurIPS**, **CVPR**, **ICLR**），我们需要结合你的大四下半学期进行全周期的甘特图规划。

| 阶段 | 时间跨度 | 学生状态 | 关键里程碑 (Milestones) | 对应会议/动作 |
| --- | --- | --- | --- | --- |
| **阶段 0：破壳期** | 大四下 (2 月 - 6 月) | 候补/远程 | 核心破局点。利用大四空闲时间，远程复现目标导师 2024/2025 年的论文。产出"复现报告"及"改进提案"。发送 **Cold Email** 建立联系 | 建立联系 (**Networking**) |
| **阶段 1：入局期** | **MSc Year 1** (9 月 - 12 月) | 在校生 | 选课即科研。选修目标导师的课程（如 **CMSC5707**），将课程 **Project** 做成 **Workshop** 级别论文。进入实验室 **Reading Group** | **CVPR 2026** (11 月截稿) - 冲刺/**Workshop** |
| **阶段 2：深耕期** | **MSc Year 1** (1 月 - 5 月) | 在校生 | 全职科研状态。此时应已正式加入实验室。利用寒假和学期完成核心实验 | **NeurIPS 2026** (5 月截稿) - 主力战场 |
| **阶段 3：爆发期** | 暑假 (6 月 - 8 月) | 实习生 | 借力打力。申请**上海AI Lab**或**InnoHK**的 **Research Intern**，利用更多算力冲击下一篇 | **ICLR 2027** (9 月截稿) |
| **阶段 4：收官期** | **MSc Year 2** (9 月 - 12 月) | 延毕/毕业 | 成果收割。处理 **NeurIPS** 的 **Rebuttal**，撰写 **CVPR 2027** 投稿。申请 **PhD** | **CVPR 2027** (11 月截稿) |

## 3. 解决"先有鸡还是先有蛋"的终极战术手册

大多数 **MSc** 学生面临的死循环是：想进好实验室（如 **MMLab**）需要有顶会论文，但没有好实验室指导就发不出顶会论文。要打破这个循环，不能靠"求学"的心态，而要靠"带资进组"——这个"资"不是钱，而是基于代码复现能力的工程红利。

### 3.1 战术一：精准复现与"改进提案" (The Reproduction-Improvement Proposal)

教授们每天收到几十封泛泛而谈的邮件。唯一能让你脱颖而出的，是一份实打实的技术报告。

**执行步骤**：

1. **锁定目标**：从下文的导师列表中，选定一位教授（例如**李鸿升教授**），下载他最近的一篇论文（例如 **WorldVLA**）
2. **代码外科手术**：去 **GitHub** 找到官方代码（通常在 **open-mmlab** 或项目主页）。配置环境，跑通 **Inference（推理）** 和 **Evaluation（评测）**
3. **关键动作**：在几个边缘 **Case** 上测试模型。例如，**WorldVLA** 在处理"透明物体"或"快速运动物体"时是否会失效？
4. **撰写"Gap Analysis"报告**：不要只说"我跑通了"。要说："我发现 **WorldVLA** 在处理长序列动作时，第 15 帧后的视觉一致性下降了 20%（附图表）。这可能是因为自回归生成的累积误差。我尝试引入了一个简单的时序一致性 **Loss**，初步实验显示能缓解这个问题。"
5. **发送邮件**：附上这份 **PDF**。这证明了你：
   - (a) 代码能力强
   - (b) 读懂了论文
   - (c) 有独立的 **Research Sense**

这是导师最看重的三个特质，远胜过 **GPA**。

### 3.2 战术二：课程特洛伊木马 (The Course Trojan Horse)

**CUHK** 的许多研究生课程直接由这些大牛教授讲授。这是接触他们的唯一"合法"且"低门槛"渠道。

**策略**：

- **查看课程表**，选修目标教授的课（如 **CMSC5707 Advanced Topics in AI**）
- **执行**：在第一节课就坐在前排。利用 **Office Hour** 去问关于他最新 **Paper** 的问题，而不是作业题
- **期末 Project**：直接向教授提议："能否将您的某篇最新论文的 **Follow-up** 工作作为我的期末 **Project**？"一旦教授同意，你就实际上进入了"准组员"的考核期。做好了，顺理成章转为 **RA**

### 3.3 战术三：利用 SURP 与 暑期研习 (Summer Research)

如果你目前还是大四学生，**CUHK** 每年举办 **Summer Undergraduate Research Programme (SURP)**。这是一个官方的暑期科研通道，允许海外/校外本科生来 **CUHK** 做 8 周科研。

- **申请时间**：通常在年初（1-2 月）
- **价值**：这是官方背书的"试用期"。如果你能申请到这个，你就直接绕过了 **Cold Email** 的筛选

## 4. 核心导师矩阵与实验室深度调研 (VLA/WM/VLM)

本部分将对 **CUHK** 在相关领域的导师进行"显微镜式"的调研。调研内容严格基于 2024-2025 年的发表记录及官网信息，剔除已离职或不活跃的教授。

### 4.1 李鸿升 (Hongsheng Li) —— MMLab 的生成式AI掌舵人

**实验室地位**：**CUHK MMLab（多媒体实验室）** 的核心 **PI** 之一。**MMLab** 是亚洲深度学习的黄埔军校，资源极其丰富，与**商汤科技（SenseTime）** 及**上海AI Lab**有极深的渊源。

**研究方向匹配度**：

- **VLA (Vision-Language-Action)**: ⭐⭐⭐⭐⭐
- **World Models（世界模型）**: ⭐⭐⭐⭐⭐
- **VLM / Generative AI**: ⭐⭐⭐⭐⭐

#### 2024-2025 核心工作深度解析

根据最新的发表记录，**李鸿升教授**团队在 2025 年迎来了爆发，单年 **NeurIPS** 接收 13 篇，**ICLR** 接收 15 篇。

##### (1) WorldVLA: 具身智能的世界模型

**代表作**："WorldVLA: An Autoregressive Action World Model for Unified Action and Image Understanding and Generation"

**技术内核**：

- **痛点**：传统的 **VLA** 模型（如 **Google** 的 **RT-2**）只是一个"策略模型（**Policy Model**）"，输入图像，输出动作。它不懂"如果我做了这个动作，世界会变成什么样"
- **创新**：**WorldVLA** 引入了**世界模型（World Model）** 的概念。它不仅输出动作，还预测未来的视频帧。这是一个"理解+生成"的双向模型
- **架构**：利用 **MLLM（多模态大语言模型）** 作为底座，通过自回归的方式同时生成 **Action Tokens** 和 **Image Tokens**

**给你的机会（Research Gap）**：目前的 **WorldVLA** 生成的未来视频可能在物理规律上不够严谨（例如物体穿模）。

**提案方向**：结合 **3D Gaussian Splatting (3DGS)** 来增强 **WorldVLA** 的物理一致性。如果能证明引入 3D 先验能让机器人的规划更准确，这就是一篇 **NeurIPS 2026**。

##### (2) 视频生成与物理模拟 (Generative World Simulator)

**代表作**：

- "GS-DiT: Advancing Video Generation with Pseudo 4D Gaussian Fields"
- "Lumina-T2X: Transforming Text into Any Modality... via Flow-based Large Diffusion Transformers"

**技术内核**：实验室正在大力押注 **Diffusion Transformers (DiT)** 和 **Flow Matching** 技术。特别关注 3D 生成与视频生成的结合。**GS-DiT** 试图用高斯泼溅技术解决视频生成中的时间一致性问题。

**给你的机会**：如果你擅长数学（流形、微分方程）或图形学（**Rendering**），可以切入这个方向。

**提案方向**：研究如何用 **Lumina** 架构生成不仅好看、而且符合物理动力学（**Dynamics-aware**）的视频，用于 **Sim-to-Real** 的机器人训练数据生成。

**联系策略**：

- **招生信号**：明确挂出 "Hiring PhD students... for 2026 Fall"。主要方向就是 **Embodied AI** 和 **Generative Models**
- **竞争**：极其激烈。必须带具体的 **Project Proposal** 去联系
- **联系人**：除了发给教授，建议同时抄送给一作的 **PhD** 学生（通常在论文第一页）。**PhD** 学生往往缺干活的 **RA**，他们会向教授推荐你

### 4.2 王立威 (Liwei Wang) —— LaVi Lab (Language and Vision Lab)

**实验室地位**：计算机科学与工程学系（**CSE**）教授。**LaVi Lab** 专注于视觉与语言的深层交互，特别是推理（**Reasoning**）和落地（**Grounding**），而非单纯的生成。风格偏向严谨的算法设计。

**研究方向匹配度**：

- **VLM (Vision-Language Models)**: ⭐⭐⭐⭐⭐
- **VLA / Navigation**: ⭐⭐⭐⭐
- **World Models**: ⭐⭐⭐

#### 2024-2025 核心工作深度解析

**王立威教授**的团队在 2025 年 **CVPR** 和 **NeurIPS** 上有多篇关于 3D 场景理解与大模型结合的文章。

##### (1) 3D-LLM 与 空间智能 (Spatial Intelligence)

**代表作**：

- "Video-3D LLM: Learning Position-Aware Video Representation for 3D Scene Understanding" (**CVPR 2025**)
- "Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors" (**NeurIPS 2025**)

**技术内核**：现在的 **VLM**（如 **GPT-4V**）看图是 2D 的，不懂物体的深度和空间关系。**LaVi Lab** 致力于将 **3D 几何先验（Geometry Priors）** 注入到 **LLM** 中。他们利用视频流重建 3D 点云特征，然后对齐到 **LLM** 的特征空间。

**给你的机会**：这是一个非常前沿且有深度的方向，被称为"空间智能"。

**提案方向**：目前的 **3D-LLM** 大多是静态场景。你可以提议研究"动态场景下的 **3D-LLM**"，例如当场景中有移动的行人时，如何更新 3D 记忆模块。

##### (2) 视觉语言导航 (Vision-Language Navigation, VLN)

**代表作**：

- "Efficient-VLN: A Training-Efficient Vision-Language Navigation Model"
- "Towards Learning a Generalist Model for Embodied Navigation" (**CVPR 2024**)

**技术内核**：这是 **VLA** 的一个子集，专注于导航。重点在于效率（**Efficiency**） 和 泛化（**Generalization**）。如何让机器人在没见过的房子里听懂指令找到厕所？

**给你的机会**：如果你对强化学习（**RL**）感兴趣，这个方向很适合。

**提案方向**：结合**李鸿升组**的 **World Model** 思想，提议"基于世界模型预测的 **Efficient-VLN**"，利用预测的未来视角来辅助当前的导航决策。

**课程资源**：**王立威教授**讲授 **AIST1000 / CSCI3230 (AI导论)**。这虽然是本科课，但他可能会在课上招募优秀本科生做 **RA**。对于 **MSc** 学生，应关注他是否开设高阶 **Seminar**（如 **CMSC5707**）。

### 4.3 窦琪 (Qi Dou) —— 医疗机器人与具身智能的交叉点

**实验室地位**：**CSE** 系副教授。虽然她的背景是医疗影像分析（**Medical Imaging**），但近年来她非常强势地切入了手术机器人（**Surgical Robotics**） 和 具身智能（**Embodied AI**） 领域，发表了 **Science Robotics** 级别的文章。

**研究方向匹配度**：

- **VLA (Surgical Domain)**: ⭐⭐⭐⭐⭐
- **Sim-to-Real**: ⭐⭐⭐⭐⭐
- **VLM Applications**: ⭐⭐⭐⭐

#### 2024-2025 核心工作深度解析

**窦教授**的研究具有极高的应用价值和技术壁垒（需要懂机器人控制）。

##### (1) 手术具身智能 (Surgical Embodied Intelligence)

**代表作**：

- "Surgical embodied intelligence for generalized task autonomy" (**Science Robotics 2025**)
- "Surgical Action Planning with Large Language Models"

**技术内核**：将 **LLM/VLM** 用于手术机器人的任务规划（**Task Planning**）。例如，医生说"缝合伤口"，**VLM** 将其分解为"持针"、"穿刺"、"打结"等一系列原子动作。**Sim-to-Real**：在仿真环境（如 **SurRoL**）中训练策略，然后迁移到真实达芬奇机器人上。

**给你的机会**：这是一个极好的差异化赛道。通用 **VLA**（如操作机械臂抓杯子）竞争白热化，但手术 **VLA** 门槛高，竞争相对小。

**提案方向**：利用 **World Model** 来模拟手术中的软组织形变（**Deformation**）。手术场景最大的难点是组织是软的，碰一下就会变。如果你能提出一个"基于世界模型的软组织形变预测与控制框架"，这将是极具分量的工作。

**联系策略**：如果你有机械工程、控制理论或医学背景，你会比纯 **CS** 学生更有优势。即使是做通用 **AI** 的学生，也可以申请她的实验室，因为底层的 **VLM** 和 **RL** 算法是通用的。

### 4.4 其他关键人物与潜在机会

#### (1) 岳翔宇 (Xiangyu Yue) —— 多模态对齐专家

- **实验室**：**MMLab / ARISE Lab**
- **方向**：**Data-Centric Embodied AI**，**Multimodal LLMs**
- **代表作**："OneLLM"。这篇论文试图用一个框架对齐所有模态（音频、视频、点云、文本）
- **机会**：如果你对数据合成（**Data Synthesis**） 感兴趣，**岳教授**正在研究如何生成数据来训练具身智能

#### (2) 林达华 (Dahua Lin) —— 隐形的大佬与上海AI Lab通道

- **地位**：**CUHK IE** 系教授，**上海人工智能实验室（Shanghai AI Lab）** 的领军人物
- **关键信息**：虽然他本人在 **CUHK** 的日常指导可能较少（因忙于**上海AI Lab**），但他是通往**上海AI Lab**海量算力和数据的超级接口
- **InternLM (书生·浦语)**：这是**上海AI Lab**发布的一系列大模型，背后有**林达华**团队的巨大贡献
- **策略**：如果你想做大模型预训练（**Pre-training**） 这种需要几千张卡的工作，必须联系**林达华教授**，并申请去**上海AI Lab**实习。这是在学校实验室很难完成的量级

#### (3) 关于 Bolei Zhou 和 Wanli Ouyang 的现状说明

- **Bolei Zhou (周博磊)**：已离职前往 **UCLA** 任教。不要以找导师的名义联系他，但可以引用他的工作（如 **Network Dissection**）作为背景
- **Wanli Ouyang (欧阳万里)**：目前主要身份是 **上海AI Lab** 教授，虽然可能在 **CUHK** 仍有挂名或合作，但实质性的指导可能发生在上海。如果你愿意去上海实习，他是一个极佳的选择，特别是在 **AI4Science** 和 **Object Detection** 领域

## 5. 详细课程体系与"以课养研"地图

**CUHK** 的 **MSc** 课程设置非常灵活。为了科研，你不能选"水课"，必须选那些能做 **Project** 且由目标导师授课的硬课。

### 5.1 核心推荐课程 (High-Yield Courses)

| 课程代码 | 课程名称 | 授课教授 (可能) | 战略价值 | 行动指南 |
| --- | --- | --- | --- | --- |
| **CMSC5707** | Advanced Topics in AI | 轮换 (通常是大牛) | ⭐⭐⭐⭐⭐ | 这门课通常没有固定教材，而是读最新的 **Paper**。这是你复现 **Paper** 并获得教授反馈的最佳舞台。目标：期末 **Project** 是一篇 **ArXiv Preprint** 的雏形 |
| **CMSC5720 / 5721** | Project I / II | 自选导师 | ⭐⭐⭐⭐⭐ | 必选。这是 **MSc** 学制中唯一官方承认的"科研时间"。你必须在第一学期初就联系好导师（如**李鸿升**或**王立威**），注册这门课。这相当于用学分换取了进入实验室的门票 |
| **AIMS5702** | AI in Practice | - | ⭐⭐⭐⭐ | 侧重系统实现和分布式训练。对于想去 **MMLab** 做大模型训练的学生，掌握 **DeepSpeed**、**Megatron-LM** 等分布式框架是核心加分项 |
| **CMSC5711** | Image Processing & CV | **李鸿升 (Hongsheng Li)** | ⭐⭐⭐⭐ | **李鸿升教授**的招牌课。表现优异者（**Top 5%**）常被邀请加入实验室。作业一定要"**Over-deliver**"，做超出要求的探索 |
| **CMSC5738** | Semantic Computing / NLP | - | ⭐⭐⭐ | 如果你想做 **VLM** 中的 **Language** 部分，需要补足 **NLP** 的基础 |

### 5.2 选课陷阱规避

- **避免**：过多选修偏管理或纯应用的课程（如 **IT Project Management**, **Financial Tech**），除非你打算毕业直接工作
- **注意**：**MSc** 学生可以选修少量 **CSCI 5000/6000** 级别的课程（通常是给 **PhD** 开的）。这些课难度大，但同学都是 **PhD**，是建立学术社交网络的好地方

## 6. 科研实战：技术深潜与选题建议 (Technical Deep Dive)

为了让你的 **Cold Email** 和 **Proposal** 言之有物，本节提供三个具体的、结合 **CUHK** 导师兴趣的选题方向。

### 6.1 选题方向 A：Consistent WorldVLA (一致性世界VLA)

- **目标导师**：**Hongsheng Li**, **Liwei Wang**
- **背景**：现有的 **WorldVLA** 在长视频预测中，物体的大小、形状会发生漂移（**Drifting**），导致幻觉
- **方法论**：引入 **3D Gaussian Splatting (3DGS)** 作为中间表征。不同于直接生成像素，模型预测下一帧的 3D 高斯参数，然后渲染成图像。这样天然保证了 3D 几何的一致性
- **话术**："I propose Gaussian-WorldVLA, which predicts the evolution of 3D Gaussians conditioned on actions, ensuring multi-view consistency for robotic planning."

### 6.2 选题方向 B：Sim-to-Real Medical VLA (虚实迁移医疗VLA)

- **目标导师**：**Qi Dou**
- **背景**：医疗数据太少，**VLA** 很难训练
- **方法论**：利用 **Generative World Model** 生成无限的合成手术视频（包括罕见的出血、并发症场景），并自动标注 **Action Label**，用于训练 **VLA**
- **话术**："Leveraging Video Diffusion Models to synthesize diverse surgical complications for robust VLA training, tackling the data scarcity in medical robotics."

### 6.3 选题方向 C：Token-Efficient VLM (高效VLM)

- **目标导师**：**Liwei Wang**, **Xiangyu Yue**
- **背景**：处理视频的 **VLM**（如 **Video-LLM**）**Token** 数量爆炸，显存不够
- **方法论**：研究一种自适应 **Token** 剪枝（**Adaptive Token Pruning**） 机制，只保留与当前 **Question** 相关的视频区域 **Token**
- **话术**："An Information-Theoretic Token Pruning method for Video-LLMs, reducing inference cost by 60% while maintaining reasoning accuracy."

## 7. 总结与行动清单 (Actionable Checklist)

### 7.1 现在立刻做 (Pre-arrival, Today - Aug 2025)

- **下载论文**：打包下载本报告提到的所有 **Paper**（**WorldVLA**, **Video-3D LLM**, **Surgical embodied intelligence**）
- **代码复现**：在 **GitHub** 上 **Fork open-mmlab** 或 **LaVi-Lab** 的相关仓库，跑通 **Demo**
- **大四 Project**：如果你大四还有毕业设计，强行将题目改为上述方向之一。这样你就有半年的全职时间做这个，产出一篇高质量的 **Report**
- **联系导师**：在 5-6 月左右，当你有了初步结果，发送 **Cold Email**。申请"暑期远程实习"或"入学前 **Visiting**"

### 7.2 入学后做 (Sep 2025 - Dec 2025)

- **抢课**：注册 **CMSC5720 Project I**，并锁定导师
- **刷脸**：每周参加 **MMLab** 的 **Reading Group**（留意邮件通知或实验室主页）
- **第一篇投稿**：目标是在第一学期结束前，将你大四的工作整理投递一个 **Workshop** 或作为下一篇大文章的 **Baseline**

### 7.3 长期规划

- **申请延期**：如果在第一年结束时（2026 夏）你已经有一篇在投，且实验进展顺利，果断申请将毕业时间规划在 2 年，利用第二年的时间去 **上海AI Lab** 或 **InnoHK** 实习
- **转 PhD**：**CUHK** 很多 **MSc** 学生通过这种方式成功转为本校 **PhD**。如果你表现出"不用教就能干活"的能力，教授留下你的概率极大

---

## 结语

在 **CUHK**，资源是溢出的，但竞争也是残酷的。**MMLab** 不缺想做科研的学生，缺的是能定义问题并解决问题的 **Engineering Researcher**。通过上述的"带资（代码/复现）进组"策略，你将彻底解决"先有鸡还是先有蛋"的问题，从被动的申请者转变为主动的合作者。

祝你在沙田的两年，不仅收获学位，更收获通往顶级科研殿堂的入场券。