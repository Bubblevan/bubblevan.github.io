---
slug: 22-dec-2025
title: 12-22
authors: [bubblevan]
tags: []
date: 2025-12-22
---

## 今日总结

把个人网站从**Docusaurus**迁移到**Hugo**了，原因是Docusaurus自定义MDX组件太麻烦了，样式修改也是一坨屎。至少Hugo可以通过F12查看元素的Box了，可喜可贺，晚点写一下针对Hugo自定义组件的博客。

- **docs** 更适合结构化、可复用的技术文档
- **blog** 更适合经验总结、思考、项目回顾

---

12.26，圣诞节的后一天，这周六是生仪的新年晚会，我觉得可以去参加一下蹭一下食物和伴手礼。抽奖我是不抱希望的。

---

**xlab的Outlier 诺亚方舟系列**，刚好更新到了[第三期](https://mp.weixin.qq.com/s/H5_yvOeehNOhEMMYZvWFTw?scene=1&click_id=7)——是**农玉俊（Aninurm）**大佬。第二期是电赛分享，第一期是创业分享，我觉得都是不错的经历，不过还是这个读完更有启发（建设性）一些。

| 课程/资源 | 来源 | 解决的核心问题/影响 |
|---------|------|------------------|
| CS50x | Harvard | 攻克了 C 语言指针等底层概念的困扰 |
| CS61B | UCB | 掌握数据结构（FDS），使其在校内课程中游刃有余 |
| 6.S081 (xv6) | MIT | 深入操作系统内核，这也是他拿到 MSRA offer 的关键筹码 |
| 《生存手册》 | 上海交大 | 观念转变：对大学教育祛魅，意识到自学的必要性与合法性 |
| CSDIY 体系 | 互联网 | 路径选择：确立了以项目驱动、自主掌控进度的学习范式 |
他的历程是一个不断**"向外验证生存能力"**的过程，每一站都有明确的成长逻辑：

1. **初创公司（18人规模）** —— **生存验证**
   - **契机**：浙大 CC98 论坛校友招募
   - **收获**：确认了自学得来的技能完全能胜任真实的商业开发
   - **思考**：意识到大二学生通过自学也能拥有"生存能力"，从而敢于放弃对绩点和保研的执着

2. **微软亚洲研究院 (MSRA)** —— **无人区探索**
   - **契机**：凭借 MIT 6.S081 项目经历通过面试；通过"免听申请"与"行政博弈"换取异地实习时间
   - **收获**：虽然半年没出 Paper，但练就了阅读源代码和处理复杂系统 Bug 的"绝活"
   - **思考**：接受了科研中"颗粒无收"的常态，磨练了钻研的耐性，看清了学术界的真实样貌

3. **Google (上海)** —— **视野与从容**
   - **契机**：在入职 MSRA 前已通过 Google 面试流程
   - **收获**：体验了顶级大厂的包容文化（Coffee Chat）、高薪报酬与奢华环境
   - **思考**：这种"云端"的体验给了他一种笃定感——证明了自己选的路（自主路径）彻底走通了，从而获得了对未来选择的豁达

> 假如明天学校的评价体系崩塌了，没有任何证书能证明我的能力，我手头拥有的技术积淀或项目经验，是否足以让你在真实的商业世界里生存下去？

如果是一年前的我，答案是否。

因此，我允许自己在大四的这一年经历一段**"颗粒无收"但"筋骨渐强"**的时期，等我熬过了这一年之后，再来评价那些无法写进简历、但深刻改变了你思维方式的挫败。

> **BTW** 我感觉将来初创实习不用像现在这样无头苍蝇找项目，也可以找个课程来做啊？
> 
> - 比如 **UC Berkeley CS285** (Deep Reinforcement Learning)，它的 **Homework 5 和 6** 非常接近工业界水平，我可以尝试将课程中的算法在 **Isaac Gym/Lab** 中复刻，训练一个能走梅花桩的 **Go2** 模型。
> - 又或者 **Stanford EE 381** (Sensorimotor Learning for Embodied Agents)，关注该课程的 **Final Project** 案例，做一个基于 **OpenVLA** 剪裁版的微调项目
> - 当然 **CS336** 这些 Language Modeling from Scratch 的也不能忘，就是信息太多太 overwhelming 了！！
---
### [高效省时、速成薄肌的经验分享](http://xhslink.com/o/6Vl03qZMfog)

我通过前天的锻炼算是进一步理解了上面的内容——练完胸后胸不痛，**三头**一直痛了两天，一看才发现原来**肩和臂不是一个东西**，原来练胸也可以练臂，进一步认同起下面的观点，坚持**胸肩背三分化**了。

**前天练胸**：
- 纯杠铃无片做了 **2组12次** 水平卧推
- 蝴蝶机夹胸 **3组**
- 器械卧推 **3组**
- 没做哑铃，感觉是**窄距握法**导致的：在杠铃卧推中，握距越窄，肘关节屈伸的幅度就越大，力量会大量向**肱三头肌（三头）**倾斜

**今天我练背**：
- 高位下拉（6个铁片3组，不知道多重）
- 坐姿划船（7个铁片4组）
- 单臂杠铃（20kg 3组）
- 蝴蝶机反向飞鸟（没做几次，因为做不动，拿5kg的哑铃飞鸟也飞不起来）
- 每组都是 **12次**

就照文章说的，采用**胸背肩胸背肩加一天休息（3+3+1）**的循环。**胸日**带上三头，**背日**带上二头，**肩日**重点练中束。每天训练后加**30分钟椭圆机**（不爬坡的原因是，爬坡脚上容易起水泡），再花**15分钟练腹肌**。我腿本身就粗（短跑+有氧导致的）没必要练。

文章里推荐说：
- **练胸**：多做上斜哑铃卧推和低位绳索夹胸
- **练背**：多做反手引体向上和高位下拉
- **练肩**：站姿侧平举和绳索面拉

明天再看看分别都是什么动作。

---

### [PhD期间如何保持科研干劲避免burn out？](https://www.zhihu.com/question/658848345/answer/1986056522531366896?utm_psn=1986535202412045099)

防止 **Burnout** 的第一要素是让项目够**"酷"**。用**多模态大模型**做感知比用复古 filter 更有趣。这是热爱的要素，核心方法一定要用**最前沿的、最热门的**，较大的挑战性和一定的高风险性，能够给你带来足够的多巴胺刺激。

文里对**正反馈**进行了分类：

- **T3级**：论文引用增加、代码库加星、读到让人神清气爽的论文、组会得到peers/mentor的认可（可能有的人会把这个提高级别）
- **T2级**：解掉大bug、项目有了阶段性进展、写作文思泉涌、作品在社交媒体有较好的反响、得到同领域专家的认可
- **T1级**：中了顶会/顶刊论文、申请到了好的实习岗位
- **T0级**：博士答辩成功，找到心仪的工业界/学术界/or 创业的岗位或者开开心心回家继承家产（真的见过读完博衣锦还乡，继承家产的）

第三点则是**体育爱好**了，见上。

---
### [Diamond7d](https://xhslink.com/m/67bg6TsE1NX)

这位博主是保研**吉林大学**的学长，里面是他自己分享的**LLM学习**的自己总结的内容。

他的路径可以概括为：**打牢底座** → **专项突破（RL+LLM）** → **硬核复现** → **寻求落地**。

#### A. 深度学习与框架（已完成）

- **李沐《动手学深度学习》**：系统刷完 **Pytorch** 部分，并跟着敲了一遍 **Transformer** 结构
- **HuggingFace Transformers 实战**：跟着博主"你可是处女座啊"跑通了项目，熟悉了从数据到模型的全流程
- **论文研读**：精读了 **Transformer** 和 **BERT** 的原始论文

#### B. 强化学习（RL）专项（重点攻克）

- **西湖大学《强化学习的数学原理》**：听了两遍。第一遍晕了，第二遍强行理解了数学推导
- **王树森《深度强化学习》**：系统梳理了知识点，配合莫烦的 RL 课程
- **代码实践**：跑通了 **Gym** 实例（如小木棍平衡），并深入研究了 **PPO**、**TRPO** 等算法，拓展到 LLM 中的 **DPO**、**GRPO** 算法

#### C. LLM 大模型进阶（正在进行）

- **Stanford CS336** (Language Modeling from Scratch)：这是他最痛苦但也最具价值的部分。目前进度在 **Assignment 1 & 2**，正在死磕 **Flash Attention 2** 的底层优化
- **MiniMind / TinyZero**：计划从零复现微小规模的模型，用于理解模型生成的全过程
- **RAG & Agent**：阅读了 **All-in-RAG** 文档，学习 **Hello Agent** 项目，掌握了最新的 **LangChain 1.0**

很多人学大模型止步于"怎么调 **RAG** 接口"，而他选择去写 **Flash Attention 2** 和从零实现 **Transformer**。这个其实就是我一直想做、但因为"怕浪费时间"或"怕没结果"而迟迟未动的事。一直以来依赖**vibe coding**，其实不利于面试的实力积累与个人自信。

---

### [具身智能技术路线科普-哔哩哔哩](https://b23.tv/1K8gl5n)

没啥好说，综述性质，还没来得及看。

---

### [理想砍掉BEV与token化直接用OCC稀疏注意力](http://xhslink.com/o/4EuRldcsvXL)

跟**XPeng**那篇**VLA without L**的类似，这个方向的**story**目前比较受欢迎，不过我暂时没有资源和实力去做。

---

### [RL-VLA综述：预训练到落地的完整路线图](http://xhslink.com/o/5tt6ciABuv7)

一篇综述论文，讲**RL**对**VLA**的作用。主要这一点比较有意思：

**三大Action建模路线，各有RL优化策略**：
- **自回归VLA（OpenVLA）**：token级RL，**TGRPO/GRPO**稳定训练
- **生成式VLA（π0）**：序列级RL，**πRL**用**Flow-SDE**处理概率近似
- **双系统VLA（Hume）**：价值对齐，避免**VLM**规划与**VLA**执行脱节

**π0系列演进**清晰展示了**Flow Matching**如何从纯生成走向RL优化（π0→π0.6引入**RECAP**→πRL实现在线RL）

**综述给出三条路**：
- **Potential-based奖励塑形**：密集反馈不改最优策略
- **主动探索**：**Plan-Seq-Learn**用**LLM**规划任务相关空间
- **世界模型rollout**：**VLA-RFT/World-Env**生成合成经验

对比**Waymo飞轮**：**VLA**挑战更复杂——多模态观测、实时物理控制、安全约束都比自动驾驶严苛。

**真机部署的系统性解法**：
- **Sim-to-Real**：域随机化（**SimpleVLA-RL**零样本迁移）、数字孪生（**RoboTwin2.0**数据飞轮）
- **人在环路**：**HIL-SERL**人类纠偏兼顾安全与效率、**ConRFT**离线+在线混合训练
- **自主恢复**：**R3L**多起点训练、**RECOVER**语义感知恢复规划

---

争取做到**一日一paper阅读**、**一力扣代码**、**一实习预备**+**web开发**赶紧搞定+傻逼**habitat**跑不起来，开源的代码也有问题。

## 技术笔记

- [RaspberryPi 4b 上部署小智 MCP 服务](/docs/self-study/embeded/raspberrypi-xiaozhi/)

## 明日计划


