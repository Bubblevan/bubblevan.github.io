---
slug: 28-dec-2026
title: 12-28
authors: [bubblevan]
tags: []
date: 2025-12-28
---
## 今日总结

### 开发计划

参考：[Gemini 对话](https://gemini.google.com/app/273342ce9b9c4444)

- **Week 1**：跑通 **Habitat-Lab** 的 **PointNav** 任务，确保你能拿到深度图并转成 **Top-down Map**
- **Week 2**：跑通 **MID** 的 Inference Demo。输入一段 numpy 轨迹，看它吐出来的预测准不准
- **Week 3**：缝合。写上面的 `act` 函数（核心循环：1.感知 → 2.预测 → 3.融合 → 4.规划）。先别管 **IAD**，先用简单的线性预测画圈，跑通 **FMM**
- **Week 4**：替换。把线性预测换成 **MID/IAD**，加上高斯热力图

### 研究思路

我已经初步确定了，从"视觉感知"（从图像中识别出行人坐标）和"路径预测"（根据坐标预测未来轨迹）解耦的角度入手：

- **视觉感知（A）**：保留 **SocialNav-Map** 的几何投影，不训练
- **路径预测（B）**：仅训练 **IAD** 模型（在离线数据集上），让它成为一个强大的"预言机"
- **决策规划**：依然是确定性的数学求解（**FMM**），不需要与环境交互试错

### A. Problem Definition: Decoupled Social Navigation

**问题定义：解耦式社交导航**

我们将社交导航任务形式化为一个在动态环境 $S$ 中的**部分可观测马尔可夫决策过程（POMDP）**，但在求解时将其解耦为状态估计与确定性规划两个子问题。

#### 1. 环境与智能体

环境 $S$ 包含静态障碍物 $\mathcal{O}_{\text{stat}}$ 和 $N$ 个动态行人 $H = \{h_1, ..., h_N\}$。智能体需从起始位姿 $p_0 \in \mathbb{R}^3$ 导航至目标位置 $g \in \mathbb{R}^2$。

每个人类 $h_i$ 的状态由其历史轨迹定义：

$$\mathbf{X}_{1:t_{\text{obs}}}^i = \{ (x_\tau^i, y_\tau^i) \mid t-t_{\text{obs}} \le \tau \le t \}$$

#### 2. 观测空间 (Observation Space)

在时刻 $t$，智能体接收观测 $O_t = (V_t, P_t, \mathcal{H}_t)$：

- $V_t \in \mathbb{R}^{H \times W}$：深度图像输入（Visual Input）
- $P_t \in SE(2)$：智能体当前的全局位姿（Pose）
- $\mathcal{H}_t = \{ \mathbf{X}_{1:t_{\text{obs}}}^1, ..., \mathbf{X}_{1:t_{\text{obs}}}^N \}$：场景中所有检测到的行人的历史观测坐标序列

#### 3. 目标 (Objective)

我们的目标是寻找一个映射函数 $f: O_t \to a_t$，生成动作 $a_t$（速度指令），使得智能体轨迹 $\zeta$ 满足：

$$\min_{\zeta} \int_{0}^{T} C_{\text{total}}(\zeta(t)) dt$$

**受限于**：

- **安全性约束**：$\forall t, \min_{i} \| \zeta(t) - \text{Pos}(h_i, t) \| > d_{\text{safe}}$（与未来不确定的行人保持距离）
- **零样本约束 (Zero-Shot Constraint)**：函数 $f$ 中的规划模块不得包含需要在线强化学习（**RL**）的参数，必须基于显式地图（**Explicit Map**）进行解析求解

### B. Methodology: Intention-Aware Map-Based Navigation

**方法论：基于意图感知的地图导航框架**

本方法提出一种 **IAD-Map (Intention-Aware Diffusion Map)** 框架，将导航解耦为三个数学模块：几何感知构建、概率意图预测、势场路径规划。

#### 1. Perception: Static Map Construction (几何感知)

沿用 **SocialNav-Map** 的确定性几何变换。利用深度图 $V_t$ 和相机内参 $K$，通过几何投影构建以智能体为中心的局部静态占用地图 $M_{\text{stat}}$。

对于每个像素 $(u, v)$，其在体素空间中的映射为：

$$P_{\text{voxel}} = \Psi(K^{-1}, V_t(u,v), R_x, R_z)$$

静态占用地图 $M_{\text{stat}}(x, y)$ 通过沿高度轴积分得到：

$$M_{\text{stat}}(x, y) = \sum_{z=z_{\text{min}}}^{z_{\text{max}}} \mathbb{I}(P_{\text{voxel}}(x, y, z))$$

这部分不含任何学习参数，保证了对静态环境的绝对忠实。

#### 2. Prediction: Intention-Aware Diffusion (概率意图预测)

引入 **IAD** 模型替换原有的线性回归，作为独立的"预言机"模块。给定观测历史 $\mathcal{H}_t$，我们使用预训练的 **Intention-Aware Diffusion Model (IAD)** 来预测未来的多模态分布。

与 **SocialNav-Map** 的线性外推不同，我们模拟人类的意图（**Intention**）。对于每个行人 $h_i$，我们计算两个关键意图分量：

**短期意图 (Short-term Intention) $I_{\text{short}}^i$**：利用残差极坐标建模，捕捉瞬时的方向变化 $\Delta \theta$ 和速度幅值 $\Delta r$：

$$I_{\text{short}}^i(t) = \{ (\theta_\tau^i, r_\tau^i) \}_{t+1}^{t+T_{\text{pred}}}$$

其中 $\theta$ 和 $r$ 通过递归累加网络预测的残差 $(\Delta \theta, \Delta r)$ 获得。这解决了线性模型无法预测转弯的问题。

**长期意图 (Long-term Intention) $E_{\text{long}}^i$**：利用 **Token-based** 预测器生成 $L$ 个候选终点集合及其置信度概率：

$$E^i = \{ (e_1^i, p_1^i), ..., (e_L^i, p_L^i) \}, \quad \text{where } \sum p_l = 1$$

这捕捉了人类运动的多模态不确定性（例如，在路口可能向左或向右）。

**轨迹生成**：通过扩散过程的逆向去噪，在 $I_{\text{short}}$ 和 $E_{\text{long}}$ 的条件引导下，生成 $K$ 条可能的未来轨迹样本 $\hat{Y}_{1:T_{\text{pred}}}^i$。

#### 3. Fusion: Probabilistic Social Cost Map (概率社交地图融合)

这是 **A+B** 的核心创新点：将 **IAD** 的概率输出转化为确定性规划器可用的地图代价。为了保持 **Zero-Shot** 规划的特性，我们不直接将预测轨迹作为输入，而是将其映射为**社交代价场 (Social Cost Field)**。

对于每个行人 $h_i$ 在未来时刻 $\tau$ 的预测位置 $\hat{y}_\tau^i$，我们不再像 **SocialNav-Map** 那样生成单一的圆形障碍物，而是生成一个意图驱动的高斯混合分布（**Intention-Driven GMM**）：

$$C_{\text{social}}(x, y, \tau) = \sum_{i=1}^{N} \sum_{l=1}^{L} p_l^i \cdot \exp \left( - \frac{(x - \hat{x}_{\tau, l}^i)^2}{2\sigma_x^2} - \frac{(y - \hat{y}_{\tau, l}^i)^2}{2\sigma_y^2} \right)$$

$p_l^i$ 来自 **IAD** 的长期意图概率，自然地为高概率路径赋予更高的避让权重。协方差 $\sigma$ 可以根据短期意图 $I_{\text{short}}$ 动态调整：如果 **IAD** 预测该人速度极快（$r$ 很大），则沿运动方向拉长高斯分布，增加前方避让距离。

最终的动态导航地图 $M_{\text{nav}}$ 是静态地图与时间衰减的社交代价的叠加：

$$M_{\text{nav}}(x, y) = M_{\text{stat}}(x, y) + \lambda \cdot \max_{\tau} \left( \gamma^\tau \cdot C_{\text{social}}(x, y, \tau) \right)$$

其中 $\gamma \in (0, 1)$ 是时间衰减因子，确保规划器更重视近期的碰撞风险。

#### 4. Planning: Deterministic Path Generation (确定性规划)

回归 **SocialNav-Map** 的 **FMM** 算法，实现无需训练的动作生成。在构建好的 $M_{\text{nav}}$ 上，求解 **Eikonal** 方程 $|\nabla T(x, y)| = M_{\text{nav}}(x, y)$ 来计算到达目标点 $g$ 的最短时间场 $T$。

最优路径 $\zeta^*$ 通过沿 $T$ 的负梯度下降获得：

$$\frac{d\zeta}{dt} = -\nabla T(\zeta)$$

最终动作 $a_t$ 根据 $\zeta^*$ 的切线方向与机器人当前朝向的偏差确定，无需任何策略网络训练。

### 核心优势

- **保留了 "Zero-Shot"**：你的 Planning 还是 **FMM**，没有任何 **PPO/RL** 训练
- **隔离了 "Learning"**：所有的学习都发生在 Prediction 阶段（训练 **IAD** 模型）。这完全合理，因为预测人类行为本来就需要从数据中学习（**ETH/UCY** 数据集），这不违反 **SocialNav-Map** 的初衷
- **体现了 "Intention-Aware"**：通过将 **IAD** 的 $p_l$（概率）映射到地图的 $Weight$（代价），你优雅地解决了"多模态预测如何指导单一路径规划"的难题

基于 CVPR 2022 的 **MID (Motion Indeterminacy Diffusion)**，目前已经形成了一个相对完整的“扩散模型轨迹预测”研究脉络。这类工作的主要演进方向集中在：**采样效率（加速推理）**、**交互建模（社交关系）**、**意图引导（Goal-guided）** 以及 **架构升级（如引入 Mamba）**。

## 扩散模型轨迹预测研究脉络

### 1. 效率优化脉络：解决扩散模型"慢"的问题

**MID** 的主要痛点是推理时的多步迭代，这一支路的工作致力于在保证多样性的同时减少采样步数。

### 2. 交互与社交建模：解决多智能体协同问题

**MID** 早期更偏向单人或简单的 **Transformer** 编码，后续工作在扩散过程中更深度地植入了社会力模型或图网络。

### 3. 意图与任务引导：解决长程预测问题

这类工作认为人类行走是"目标驱动"的，扩散模型不应只是随机去噪，而应受到意图的引导。

### 4. 最新技术融合：架构与不确定性建模

随着 2024-2025 年新技术的发展，扩散轨迹预测开始引入 **Mamba** 等高效架构或更复杂的统计模型。

### 研究对比表

| 研究方向 | 论文名称 | 会议/年份 | 核心贡献 | 备注 |
| --- | --- | --- | --- | --- |
| **效率优化** | **LED: Leapfrog Diffusion Model** | CVPR 2023 | 提出了"跳跃式"扩散模型。引入可训练的 **Leapfrog Initializer**，直接学习未来轨迹的粗略多峰分布，允许采样过程跳过大量去噪步骤，大幅提升推理速度 | 是 **MID** 之后在轨迹预测扩散领域引用量极高的代表作 |
| | **GDTS: Goal-Guided Diffusion Model with Tree Sampling** | IROS 2025 | 将目标点估计（**Goal Estimation**）与扩散模型结合。核心在于 **Tree Sampling（树状采样）** 算法，利用公共路径特征减少重复计算，实现实时推理速度 | |
| **交互与社交建模** | **Social-Diffusion** | CVPR 2023 | 显式地在扩散去噪过程中加入社会交互约束。通过基于交互的去噪网络，确保生成的预测轨迹在物理上是避障的、在社交上是可接受的（**Socially acceptable**） | |
| | **TrajFine** | CVPRW 2024 / CVPR 2024 | 将扩散模型作为"精细化器（**Refiner**）"。先用基础模型生成粗略轨迹，再通过扩散过程提取智能体间的社会关系和未来交互动态，对轨迹进行微调 | |
| **意图与任务引导** | **DifTraj: Intrinsic Intention and Extrinsic Interaction** | IJCAI 2024 | 提出了第一项显式构建**意图模型（Destination Points）**的扩散预测工作。通过双阶段过程，先由意图引导预测均值和方差，再利用扩散模型模拟决策过程中的不确定性 | |
| | **MotionDiffuser** | CVPR 2023 | 实现了"可控"的多智能体预测。允许用户通过给定的引导（**Guidance**），比如避开特定区域或强制经过某点，来干预扩散模型的生成过程 | |
| **最新技术融合** | **SAMD: Stochastic-Aware Mamba Diffusion** | ICASSP 2025 | 将最新的 **Mamba (State Space Models)** 架构与扩散模型结合。利用 **Mamba** 在处理长序列数据上的线性效率，显著降低计算开销，同时通过"随机感知（**Stochastic-Aware**）"模块增强对噪声的建模能力 | |
| | **U2Diff: Unified Uncertainty-Aware Diffusion** | CVPR 2025 | 针对多智能体场景下的**不确定性（Aleatoric & Epistemic Uncertainty）**进行统一建模。在扩散过程中引入不确定性感知机制，使模型在拥挤、复杂的动态环境下更具鲁棒性 | |

如果你目前正在开展基于扩散模型的轨迹预测研究，**LED** 是必读的基础改进方案，而 **DifTraj** 和最新的 **SAMD** 代表了当前结合意图与新架构的前沿趋势。有一说一，还没有中稿的论文如[IAD](https://github.com/AISLAB-sustech/IAD) 只能提供一个idea的参考，而不能草率的基于其去做。

这个idea比较符合第一性原理，但是指标上能不能上得去就不好说了。Idea is cheap，show me the code.

## 技术文档

### 今日论文

- [SocialNav-Map](../../papers/vln/socialnav-map)
- [SAN Taxonomy Survey](../../papers/vln/san-taxonomy-survey)（还没完）
- [Falcon](../../papers/vln/falcon)
- [VLM-Social-Nav](../../papers/vln/vlm-social-nav)

可以再看看 **LOVON** 的 `deploy.py` 还有神仙文章 [VLM-Social-Nav](../../papers/vln/vlm-social-nav)。我决定最后还是不上 **VLM** 了，实机的话比较麻烦先看一下前面两者的代码考虑考虑。
### 今日练习

### 今日课程

### 今日项目

### 今日调研


## 明日计划

