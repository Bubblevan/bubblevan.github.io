---
slug: 13-Jan-2026
title: 1-13
authors: [bubblevan]
tags: []
date: 2026-01-13
---

## 今日总结
开题答辩有惊无险的过了，答而不辩疯狂道歉，谢谢王老师，谢谢叶老师，谢谢尹老师，谢谢田老师
PPT被第三者夸了，证明我的审美还是有在进步吧？但是实验确实还没开始做
哦想起来了那个开题报告和文献综述共享全部参考文献的问题还是要大改！！！
好的梳理一下时间线，三月底四月初中期答辩，所以要有所实验进展；打激光；Locomotion综述；yuedong sports开发；toB agents intern；

被njz种草了[fellou](https://fellou.ai/)还有[灵光](https://www.lingguang.com/chat)

我记得除了打包东西之外还有一件事情要做很急，但是我坐在这里就忘了。
可能是红包的事？

---

8. AI PPT 工作流

开组会时看到师兄熟练掌握各类AI，融会贯通，工作效率逆天，对小登的世界观造成巨大冲击，发现比起单个AI，效率的提升更在于总结出几套好用的工作流。

文档阅读：

- Gemini 3 Pro ：上下文能力很强，能够一次性给他几百页的PDF还有视频，音频。可以将你的报告，文献全部放进去，让他分析总结出简报和整体汇报方向。

PPT大纲：

- Qwen 3：对中文的支持比较好，将Gemini生成的数据生成为PPT结构化的大纲

- Claude 4.5：文本能力很强，同样是根据前期数据总结为PPT的md或者json

PPT制作：

- Qwen 3/ Kimi ：通过大纲生成可编辑式PPT，缺点是同质化比较严重

- Nano Banana：通过大纲直接一系列生成带文字的图片，生成不可编辑的图片式PPT，这个效果还是比较经验的，因为他的文字框架树可以做的很深，而且会自动配一些小插图。

- Figma：同样支持AI自动排版，优点是本身作为设计师用的，PPT模板会高级一点，元素的层级也会更多。也可以导出模板作为Nano的基础

PPT图片：

- Nano Banana/Chat GPT-image 对于一些特定的图片通过AI生成补充


9. AI论文阅读，组会总结工作流

这是最让lz震惊的，lz在开组会时，有一位学长被压力说一周没干什么事，学长的回应是没有找到相关论文，结果另一个学长就在组会上，通过会议语音总结，AI检索，AI阅读，图片生成，开会的30分钟就干完了另一个学长一周的汇报结果。

会议总结：

- 科大讯飞/通义听悟：都是比较好用的语音转文字总结，但是不能实时的总结，终究是一个外部工具。

- Notion：Notion的语音总结是让我很惊艳的，会实时根据会议的语音总结出笔记，学长但是做汇报时就直接实时结合了刚刚的会议内容

论文检索/阅读：

- 目前Chat GPT在文献检索方面的能力是很强，将Notion实时的总结给GPT，让他找出相关概念的论文

- 找到论文后，交给 [元宝 - AI 阅读](https://yuanbao.tencent.com/chat/ddk4eQR3ap) 进行论文阅读总结，很快并且图文结合。

报告：

- Nano Banana：可以根据你的实时内容生成图片，漫画帮助别人理解

- Chat GPT-image：可以直接根据你刚刚与Chat GPT的对话上下文生成图片，非常迅速便捷

PS：这些对于老登来说可能是家常便饭，小菜一碟，但是对于刚接触科研学习的小登来说还是太震撼了，不说用AI迭代，我们很多人连当前AI的实力都发挥不出来
---

## 技术文档

总结一下实验bench的选择
[InternVLA-N1](https://github.com/InternRobotics/InternNav)，[项目主页](https://crystalsixone.github.io/vln_pe.github.io/)
[NVIDIA COMPASS](https://github.com/NVlabs/COMPASS)核心是 Hierarchical（分层） 的：
高层 (Generalist Policy/VLA)： 比如 GR00T 模型，负责理解语言指令、进行视觉推理，并输出目标点（Waypoints）或语义动作。
底层 (Specialist/Mobility)： 这才是 COMPASS 的核心——利用 Residual RL（残差强化学习） 让不同的机器人（四足、双足、轮式）在复杂地形下稳健地执行高层发出的“移动”指令。
其他的像是VLNVerse、InterNav都还没开源完，不考虑。

后面就选择跟着AILab走了，太强了InternUtopia桃源
但是现在卡在`pip install -e .[model] --no-build-isolation`这一步了，主要是flash-attn。
安装 flash_attn 失败的核心问题是CUDA 版本不匹配（系统检测到 CUDA 12.8，但你的 PyTorch 是基于 CUDA 11.8 编译的），同时尝试从 GitHub 下载预编译 wheel 包时还遇到了网络超时，导致只能从源码编译，而源码编译因 CUDA 版本不兼容直接报错
然后Habitat和Isaac的依赖还没配，但是Checkpoint（InternVLA-N1还有DA2-vits）下好了，可以实验Server-Client
给我一种感觉，就是Bench新越好的工作，对应领域的创新点就越卷
而每一个近期的工作基本上都是自带Bench的，那么自然在其Bench上就工作的非常适配，后人用的话又难以超越，索性不用而是堆工作量再造新的Bench然后讲故事，然后又把指标刷的很慢
像是这个AILab的InternVLA-N1已经把NaVILA、NaVID等都爆了

我有一个问题，就是感觉Bench新越好的工作，对应领域的创新点就越卷
而每一个近期的工作基本上都是自带Bench的，那么自然在其Bench上就工作的非常适配，后人用的话又难以超越，索性不用而是堆工作量再造新的Bench然后讲故事，然后又把指标刷的很慢
像是这个AILab的InternVLA-N1已经把NaVILA、NaVID等都爆了

## 明日计划

