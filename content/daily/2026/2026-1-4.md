---
slug: 4-Jan-2026
title: 1-4
authors: [bubblevan]
tags: []
date: 2026-01-04
---

## 今日总结

盲走这周写一版？DP写视觉那部分，周末咱俩合一下呗

---

[读博个人成长](https://www.zhihu.com/question/1136011977/answer/1901649423131472480?utm_psn=1991111905440449748)

先完成再完美，适合大多数人为了写论文而写论文，当然远离科研的初衷但这是先完成的一部分，完成都做不到，谈何完美？这就大家说的灌水，我觉得主观灌水没有意义但是客观产生水文确实科研探索中不可避免的事情所以，哪怕知道了只能产出一篇水文，也应该先完成完成一次迭代，对个人成长的意义重大。完成几次迭代后，就应该系统地想想如何避免水文，如何做出漂亮的工作。

---

[无大算力时，作为学生，LLM 还有哪些值得做的研究](https://www.zhihu.com/question/1936111519252349787/answer/1977020498446657108?utm_psn=1991116817385666038)

在LLM研究中，避开与巨头比拼预训练规模，转向对模型行为机理、数据质量、评估体系及高效架构的深度探究，是资源有限研究者的核心出路。
真正的创新在于提出新问题或发现新现象，而非在既有任务上刷指标。例如，探究RAG中模型面对冲突信息时的决策边界，或量化对模型推理能力的损害。
| 研究方向 | 核心问题 (What) | 具体切入点与实验设计示例 (How) | 关键资源/工具 |
| :--- | :--- | :--- | :--- |
| **1. 评估与数据** | 如何客观、自动化地衡量模型/系统在复杂任务（如Agent规划、RAG忠实度）上的表现？ | **切入点**：设计针对特定场景（如长文档问答）的评估框架，综合衡量检索相关性、答案忠实度、逻辑连贯性。<br>**实验**：对比不同RAG切片策略（如语义分割v.s.固定长度）对评估指标的影响。 | RAGAS评估框架、LLM-as-a-Judge、Chatbot Arena理念 |
| **2. RAG机理深化** | 超越工程拼接，RAG系统在原理层面有哪些未解之谜？ | **切入点**：研究“**对抗性检索**”场景：当检索片段与模型内部知识冲突时，模型更相信谁？其边界条件是什么？<br>**实验**：构建包含冲突信息的数据集，系统改变冲突强度、位置，观察模型输出变化。 | LangChain/LlamaIndex源码、开源RAG系统 |
| **3. Agent认知架构** | 如何让Agent具备更复杂的记忆、规划与自我修正能力？ | **切入点**：改进Agent的**长期记忆与反思机制**，解决长任务中的误差累积问题。<br>**实验**：复现一个简易Agent框架（如ReAct），为其增加记忆存储与定期总结功能，测试其在多轮任务中的表现稳定性。 | AutoGPT、LangChain Agent、DSPy框架 |
| **4. 高效模型技术** | 如何让小模型（≤8B）在特定能力上逼近大模型？ | **切入点**：研究**高级知识蒸馏**，不仅蒸馏答案，更蒸馏思维链（CoT）推理过程。<br>**实验**：使用GPT-4生成带有推理步骤的数据，微调Llama-3-8B，并在数学推理数据集上对比蒸馏前后的性能跃升。 | 模型微调库（PEFT）、Phi系列论文、知识蒸馏论文 |
1.  **可解释性**
    使用GPT-2级别的模型即可开展。核心是去找到并**因果干预（causally intervene）** 模型中负责表征某个特定知识的**回路（circuits）**。采用**ROME**或**MEMIT**这类方法，定点修改一个事实陈述（factual statement），然后观察模型的**内部状态（internal state）** 发生了哪些**可预测的变化**。

2.  **高效推理**
    推理（Inference）的瓶颈在于**内存带宽（Memory bandwidth）**。每次生成一个token，都需要把巨大的权重参数从高带宽内存（HBM）里读取一遍，这种方式效率低下。研究目标应该是：**如何在更少的I/O操作下完成更多计算（how to do more with less I/O）**。

3.  **高效参数微调**
    一个预训练模型要适应下游任务，真正需要改变的权重所在的**子空间（subspace）** 其实是**非常低维**的。这个想法本身具有数学上的简洁美感。

4.  **无需训练的视频理解**
    这可能是最有意思的方向之一。视频（Video）不过是**一系列图像（a sequence of images）**。视觉语言模型（VLM）在静态图像上已经具备了惊人的**零样本推理（zero-shot reasoning）** 能力。那么，为什么我们不能直接利用这种能力，**动态地（on-the-fly）** 理解视频？

5.  **长上下文机制**
    去研究Transformer到底是如何利用长上下文的。它真的在看**100万token**之前的信息吗？还是说大部分的注意力分数实际上都集中在**一个很局部的窗口**里？有没有可能证明，对于某些任务，存在一种**亚二次（sub-quadratic）** 的**最小注意力模式（minimal attention pattern）**？

6.  **上下文学习的机理**
    如今谁都知道给LLM几个少样本示例（few-shot examples），它的性能会暴涨。但**为什么（HOW）**？没人能真正说清楚。将其解释为**元学习（meta-learning）** 或**隐式微调（implicit fine-tuning）**，本质上都只是在用一个黑箱去解释另一个黑箱。

7.  **AI安全**
    人工智能安全问题远不止给模型加上“护栏”，不让它说脏话那么简单。**对抗性攻击（Adversarial attack）** 和**越狱（jailbreak）** 只是冰山一角。更深层次、更根本的问题是：**我们如何保证一个越来越自主的AI系统的行为是可预测和有益的？**

**核心论点与建议总结：**
如果你没有钱、没有计算卡，就不要去跟大公司比拼规模（scale）。正确的策略是：**让他们去扩大模型的规模，你来提升自己头脑的深度（Scale up their models, scale up your brain）**。你应该专注于那些更需要**洞察力（insight）、优雅性（elegance）** 和**第一性原理思考**的研究。去识别出那些尚未成为标准研究课题的问题，然后解决它们。

#轻量化研究 #模型行为学 #评估科学 #Agent认知架构

---

## 技术文档


## 明日计划

