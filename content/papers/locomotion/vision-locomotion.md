---
title: "Locomotion 论文精读（四）Legged Locomotion in Challenging Terrains using Egocentric Vision"
---

> https://arxiv.org/abs/2211.07638
> CoRL 2022

## 研究背景
2022 年老资历，但我觉得它的“问题定义”到现在依然有效：作者先把当时流行的两阶段 pipeline（**高程图构建 → foothold/步态规划**）挑了一遍毛病，大概有三点：
- **高程图脆弱**：噪声、遮挡、位姿漂移一来，地图就容易不可信；
- **硬件门槛高**：多相机、激光雷达之类上车成本高，小平台更难堆；
- **不太像人类走路**：人类不会先建一张“完美地图”再一步步规划落脚点，更多是“看一眼前方 + 记住几秒 + 动作自适应”。

![](/paper/vision-locomotion-problems.png)
*图：小型四足在楼梯/路缘这类地形上容易“上不去/下不稳”；本文用学习到的髋外展步态来应对。*

我自己的理解是，**小尺寸机器人（例如 Unitree A1）在台阶这种离散地形上特别吃亏**—— 上台阶时脚容易被立板挡住，下台阶时机身又更容易“前栽/侧翻”。如果还沿用预编程步态，很容易出现“看起来能走，但一换地形就翻车”的情况。

所以这篇想做的是更直接的端到端：让 A1 **只用前置单目深度相机 + 本体感知**，在室内外、昼夜、城市/自然的典型复杂地形（台阶、路缘、踏脚石、缝隙）里走得稳，而且**不靠手工写死的步态模板**。

作者用“人类怎么用视觉走路”做锚点，可以概括成三条直觉：
- **不是一直盯脚下**：平地直走这种“局部可控”的场景，视觉不是必需，靠本体感知也能走；
- **复杂地形才必须看**：楼梯、踏脚石这类需要提前判断落点安全性的场景，视觉决定“踩哪里不摔”；
- **靠短期记忆和试错**：落脚动作往往依赖几秒前看到的前方地形（短期记忆），步态也不是预编程循环，而是通过交互逐渐学出来的。
## 方法论
这篇的方法我觉得非常“工程味”：目标很简单——把 **本体感知 + 前视深度图** 直接映射成 50Hz 的关节目标角（也就是端到端控制）。但作者很快就遇到一个现实瓶颈：**在 RL 训练里“渲染深度图”太贵了**，远比“查询地形高度”慢，样本量一上来就顶不住（尤其当你想并行几千上万环境）。

所以他们绕了一个我很喜欢的弯：先用一个“便宜但够用”的地形表征把策略练出来，再把能力蒸馏回真实传感器输入。整个训练是两阶段：
- 阶段 1（RL）：用 `Scandots` 这种**低成本地形几何采样**替代深度图，训练出初始策略 \(\pi^{1}\)；
- 阶段 2（监督学习）：用 \(\pi^{1}\) 生成动作监督，把能力蒸馏到最终策略 \(\pi^{2}\)，部署时只吃 **深度图 + 本体感知**。

![](/paper/vision-locomotion-pipeline.png)
*图：两阶段训练流程。先用低成本 `Scandots` 做 RL 预训练得到 \(\pi^{1}\)，再用动作蒸馏训练最终的 \(\pi^{2}\)，让策略适配真实的前视深度图输入。*

> `Scandots`：在机器人局部坐标系里预先选一组 \((x,y)\) 采样点，每个控制步只查这些点的地形高度（不用渲染整张深度图），就能抓住台阶高度、缝隙位置等几何要素，计算成本大概是深度图的一小部分。
### 阶段 1：基于 Scandots 的强化学习（仿真预训练）
**先把“会走”练出来，但尽量别把训练算力浪费在渲染深度图上**。所以这里用 `Scandots` 这种“便宜的局部几何采样”来替代深度图，训练得到策略 \(\pi^{1}\)。另一个我觉得很关键的点是：作者刻意做成**无步态先验**——不写死“走路节拍”，让适合 A1 的步态在训练中自己长出来（比如爬楼梯时自发出现的髋外展）。

1. 输入与观测设计  

| 输入 | 符号 | 我理解的含义 | 作用 |
| --- | --- | --- | --- |
| `Scandots` | \(m_t\) | 机器人局部坐标系下若干采样点的高度 | 以很低成本提供地形几何信息 |
| 本体感知 | \(x_t\) | 关节角/角速度、机身角速度、姿态信息、上一时刻动作 \(a_{t-1}\) 等 | 保证动作平滑、闭环稳定 |
| 指令 | \(u^{cmd}_t\) | 期望线速度 \(v^{cmd}_x\)、期望偏航角速度 \(\omega^{cmd}_z\) | 让策略按命令走/转 |
| 特权信息（仅 RMA） | \(e_t\) | 质心、摩擦、执行器强度等仿真可得信息 | 训练时辅助泛化，部署时去掉 |

观测我更愿意写成：\(\;o_t = (m_t, x_t, u^{cmd}_t)\;\)，RMA 版本额外拼上 \(e_t\)。

2. 算法与训练目标  
核心算法是 PPO，并用截断的 BPTT（比如 24 步）来训练带记忆的策略/编码器，既照顾时序依赖，也不至于算到爆。

训练目标可以概括成两句：**跟踪指令** + **在复杂地形上尽量别把硬件折腾坏**。所以回报函数里会同时出现：
- **能量/用力的惩罚**：直觉上是“别瞎用劲”，让动作更省；
- **指令跟踪奖励**：鼓励 \(v_x \approx v_x^{cmd}\)、\(\omega_z \approx \omega_z^{cmd}\)；
- **硬件保护项**：例如脚部 jerk、拖脚、腿部碰撞等惩罚，避免电机冲击和自撞；
- **生存奖励**：先活下来再谈走得快（每步给一个 survival reward 的味道）。

3. 训练环境设计  
阶段 1 的训练地形做得比较“课程化”：
- 地形类型覆盖楼梯、斜坡、踏脚石、缝隙、离散障碍物等；
- 同类地形从易到难排列（例如台阶高度逐渐增大）；
- 通过“能走远就升级、走不动就降级”的课程规则稳定训练；
- 叠加域随机化和观测噪声（摩擦、阻尼等参数扰动），提前把真实世界的麻烦模拟进去。


### 阶段 2：基于深度图的监督学习（政策蒸馏）
阶段 2 的目标很明确：把 \(\pi^{1}\) 在“能走”这件事上的能力，迁移到**真实可用的深度相机输入**上，得到最终部署策略 \(\pi^{2}\)。做法就是经典的动作蒸馏：用 \(\pi^{1}\) 生成“标准答案动作”，让 \(\pi^{2}\) 去模仿。

1. 核心流程：从 `Scandots` 到“深度图”  
我把阶段 2 看成三件事：
- **把深度图变成可学的特征**：先做裁剪（去掉容易遮挡的一侧），再做孔洞填充，然后下采样到 \(58\times 87\)，最后用一个卷积网络把深度图编码成低维特征 \(\tilde{d}_t\)；
- **用蒸馏而不是再跑 RL**：\(\pi^{1}\) rollout 产生动作 \(a_t\) 作为监督信号，\(\pi^{2}\) 输出 \(\hat{a}_t\)；
- **用 DAgger + 截断 BPTT**：DAgger 用来补齐“学生不擅长的状态分布”，BPTT 用来保证时序模型训练得动。

蒸馏损失可以写得很直白：最小化 \(\lVert \hat{a}_t - a_t \rVert^2\)。

2. 两种学生策略架构（Monolithic vs RMA-style）  
作者比较了两种“怎么把视觉接到控制器上”的方式，我觉得这是这篇很值得抄作业的点：

| 架构 | 输入 | 输出 | 我理解的优点 |
| --- | --- | --- | --- |
| Monolithic（整体式） | \((\tilde{d}_t, x_t, u^{cmd}_t)\) | \(\hat{a}_t\)（关节目标/偏移） | 结构最简单，端到端一把梭 |
| RMA-style（分解式） | \((\tilde{d}_t, x_t, u^{cmd}_t)\) 与 \((x_t, u^{cmd}_t)\) | \(\hat{a}_t\) | 模块化：把“感知→latent”与“latent→动作”解耦，后续换传感器更顺 |

更具体一点，分解式会学两个时序 latent：
- **地形相关 latent**：\(\hat{\gamma}_t = \mathrm{GRU}(\tilde{d}_t, x_t, u^{cmd}_t)\)
- **环境/动力学相关 latent**：\(\hat{z}_t = \mathrm{GRU}(x_t, u^{cmd}_t)\)

然后把 \((x_t, \hat{\gamma}_t, \hat{z}_t, u^{cmd}_t)\) 丢进一个基础 MLP walking policy 输出 \(\hat{a}_t\)。

### 两阶段训练的有效性数学证明（Theorem 2.1）
这段定理我不打算死抠推导细节（论文是为了给两阶段训练一个“不会离谱”的理论保证），但它传达的意思很清晰：

1. 定理前提（2 个关键假设）  
- **阶段 1 够强**：\(\pi^{1}\) 离最优不远，形式上可以写成对所有 \(s\in S\)，\(\lvert V^*(s) - V^{\pi^{1}}(s)\rvert < \epsilon\)；
- **阶段 2 模仿得够像**：对所有 \(s\in S\)，\(\lvert \pi^{1}(s) - \pi^{2}(f(s))\rvert < \eta\)，这里 \(f(\cdot)\) 表示把“阶段 1 的状态/观测”映射到“阶段 2 能看到的输入空间”；
- 再加一个常见技术条件：回报 \(R\) 和转移 \(P\) 满足 Lipschitz 连续性（小扰动不至于引发灾难性变化）。

2. 定理结论（\(\pi^{2}\) 的性能保证）  
在上述假设下，\(\pi^{2}\) 的性能与最优策略的差距存在上界，写成一类典型形式是：

\[
\lvert V^*(s) - V^{\pi^{2}}(f(s))\rvert \le \frac{2\epsilon\gamma + \eta c}{1-\gamma}
\]

直觉上就是：**只要阶段 1 够强（\(\epsilon\) 小），蒸馏误差够小（\(\eta\) 小），那阶段 2 不会差太多**。

## 实验
### 实验设置
1. 硬件平台：Unitree A1 四足机器人  
A1 的硬件约束会一路“反推”算法形态（**单目深度、低帧率、低算力**），所以作者干脆把设计理由也写得很工程化。

| 模块 | 配置 | 我理解的影响 |
| --- | --- | --- |
| 运动关节 | 12 个驱动关节（每腿 3 个） | 策略直接输出 12 维目标，**动作必须平滑**以保护电机 |
| 感知系统 | 1× Intel RealSense D435 深度相机（480×848，10±2Hz） | 单目前视，后脚看不到 → **需要短期记忆（GRU）**；帧率低 → **需要处理延迟** |
| 计算模块 | UPboard（x86）+ Jetson NX（21 TOPS） | 算力紧 → **深度图必须压缩**（裁剪/下采样/Conv 编码），不太可能跑复杂地图融合 |
| 控制频率 | \(\pi^{2}\) 以 50Hz 输出；底层 PD 以 400Hz 跟踪 | 高层要实时、低层兜底跟踪，形成稳定闭环 |

深度图预处理我按“为什么要做”来记更直观：为了应对 **噪声、尺寸、延迟**，他们做了四步：
- **裁剪**：去掉左侧 200 像素（遮挡区域本来就没用）；
- **孔洞填充**：最近邻插值补深度空洞（遮挡/反光常见）；
- **下采样**：480×848 → 58×87（算力预算决定的）；
- **延迟建模**：把 10±10ms 的传输/预处理延迟也塞回训练里，避免 sim/real 时序对不齐。

1. 仿真环境：IsaacGym + Legged Gym  
仿真这块的目标是：**把“不同难度、不同类型的地形”一次性覆盖掉**，让单一策略能泛化。
- 地形地图：20×10 网格（100 个子地形），每行一种地形（斜坡、踏脚石、楼梯、离散障碍物），从左到右难度递增（例如台阶高度 5cm→25cm）；
- 课程学习：能走到地形长度的 50% 就升级，走不动就降级（避免卡在“只会平地”的局部最优）；
- 鲁棒性：域随机化（阻尼、摩擦、质量等）+ 小幅高斯噪声（观测/传感）。

### 基线
为了把“视觉到底有没有用”讲清楚，作者设计了两个基线（训练样本量对齐，算是比较公平）：

| 基线 | 怎么做 | 想回答的问题 |
| --- | --- | --- |
| Blind（盲策略） | 把 `Scandots` 观测置零，只用本体感知 \(x_t\) + 指令 \(u^{cmd}_t\) | **纯本体感知能走到什么程度？**哪些地形“没视觉就不行”？ |
| Noisy（噪声策略） | 用“高程图 pipeline”的视角做对照：教师用无噪声高程图训练；学生用带大噪声高程图蒸馏；训练时叠加 40ms 延迟 | **高程图噪声/延迟会把方法拖成什么样？**端到端是否能绕开这个坑？ |

### 结果
仿真评估用两个指标：
- **平均前向位移**（越大越好）：能不能穿越地形；
- **平均跌倒时间**（越大越好）：稳不稳、能撑多久。

我把原表拆成“一个 Markdown 能读的版本”（数值保持不变）：

*表：仿真指标对比（平均前向位移 / 平均跌倒时间）。RMA 与整体式（MLith）在总指标上相对 Noisy/Blind 有明显优势。*

| 地形 | 位移 RMA (m) | 位移 MLith (m) | 位移 Noisy (m) | 位移 Blind (m) | 跌倒时间 RMA (s) | 跌倒时间 MLith (s) | 跌倒时间 Noisy (s) | 跌倒时间 Blind (s) |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 斜坡（Slopes） | 43.98 | 44.09 | 36.14 | 34.72 | 88.99 | 85.68 | 70.25 | 67.07 |
| 踏脚石（Stepping Stones） | 18.83 | 20.72 | 1.09 | 1.02 | 34.30 | 41.32 | 2.51 | 2.49 |
| 楼梯（Stairs） | 31.24 | 42.40 | 6.74 | 16.64 | 69.99 | 90.48 | 15.77 | 39.17 |
| 离散障碍物（Discrete Obstacles） | 40.13 | 28.64 | 29.08 | 32.41 | 85.17 | 57.53 | 59.30 | 66.33 |
| 总计（Total） | 134.18 | 135.85 | 73.05 | 84.79 | 278.45 | 275.01 | 147.83 | 175.06 |

1. 整体趋势：本文方法显著优于基线  
最“结论导向”的一句就是，**总位移与总跌倒时间都提升了 60%–90%**（RMA/MLith vs Noisy/Blind），说明端到端融合视觉之后，既走得更远，也更不容易摔。

1. 分地形看差异：哪些地形“视觉是必需品”  
- **斜坡**：视觉是“加分项”，但不是必需（Blind/Noisy 也能走一段）。不过 RMA/MLith 还是能多走大约 25%，更像是效率与稳定性的提升。  
- **踏脚石**：这是最能说明问题的一类地形——**没视觉基本等于瞎**。Blind/Noisy 的位移只有约 1m，而 RMA/MLith 能跑到接近 20m。这里“看得到前方 + 记得住几秒（GRU）”非常关键，因为后脚落点要靠之前看到的位置来补。  
- **楼梯**：RMA/MLith 相对 Noisy 的优势很夸张（最高到 6.3×）。我的理解是两点叠加：一是视觉帮它提前抬脚/调整落点，二是**无步态先验 + 训练涌现的髋外展步态**非常适配 A1 这种小平台。  
- **离散障碍物**：视觉主要用来提前规避碰撞；RMA 在这个地形上更好，整体式 MLith 反而略弱一点，可能和“整体网络对细粒度几何的利用方式”有关。

真实世界这里作者主要拿本文方法对比 Blind（Noisy 在真实世界更难做，因为你得先稳定建高程图）。

| 任务 | 地形参数 | 本文方法 | Blind | 我理解的结论 |
| --- | --- | --- | --- | --- |
| 上楼梯 | 17cm 高、30cm 深（13 级） | 成功率 100% | 成功率 0%（平均 2.2 级就撞台阶） | **小平台上楼梯离不开视觉定位** |
| 下楼梯 | 17cm 高、30cm 深（13 级） | 成功率 100%，步态平滑 | 成功率 100%，但“摔下去式”步态导致髋关节脱位 | **无视觉也许能“下去”，但会把硬件干坏** |
| 缝隙 | 26cm 宽 | 成功率 100% | 成功率 0%（直接踩空） | **视觉在判断跨越尺度上是必需的** |
| 踏脚石 | 30cm 宽、15cm 间距 | 成功率 94%（平均踩 9.4 块） | 成功率 0% | **视觉 + 短期记忆能把落脚点“记住”** |

相机设置上有一个细节值得记一下：
- 楼梯任务用 A1 内置前视相机（水平视角能看到台阶）；
- 踏脚石/缝隙任务用外接顶部相机（前视相机看不清脚下）。  
这也侧面说明了“RMA-style 的模块化”是有实际意义的：更换传感器输入时，只要接口/编码器处理得当，不一定要推倒重练整个基础 walking policy。

![](/paper/vision-locomotion-real.png)
*图：真实机器人任务对比（本文方法 vs Blind）。关键点不是“成功率高”，而是 Blind 在下楼梯会学到高冲击的跌落步态，最终造成真实硬件损伤。*

为了证明“不是只在实验室里跑得好看”，作者还做了两类更贴近真实应用的扩展测试：

1. 城市环境：高障碍 + 意外情况  
- 场景：24cm 高台阶、26cm 高路缘（接近 A1 髋高），以及“错过台阶后的恢复”；  
- 现象：策略能自己调整步态攀爬；就算视觉一时没看清，仍能靠本体感知 + 记忆把动作拉回来继续走；  
- 我理解的关键：**没有预编程步态**，所以“适配动作”是学出来的，不用人手写规则。  

1. 自然环境：不稳定地形 + 扰动  
- 场景：河床碎石、hiking 路径（树根）、沙滩（易打滑）；  
- 现象：视觉用于提前避障/避绊，本体感知用于打滑后的平衡修正；  
- 我理解的关键：训练里做的噪声与随机化，让策略对真实世界的不确定性更“耐造”。
## 小结与局限

### 综述学习

一、第一类：Legged Locomotion（四足移动控制的基础研究）  
这条线的主旋律是：从早期的模型/启发式，到“仿真训 RL → 上真机”。我自己的结论是：
- 经典方法（Model-based / Heuristic，代表 [19-31]）：在结构化场景很稳，但面对楼梯、缝隙、踏脚石这种“离散几何”，**规则很难一次写全**，工程维护成本爆炸。  
- 现代 RL（Simulation→Real，代表 [14,32-41]，以及测试时自适应 [42-52]）：能学到更强的地形适配，但大量工作仍是 **盲策略（Blind Policy）**，只用本体感知，遇到“必须先定位落脚点”的地形就很吃亏。

与本文的关系我理解成两句：
- 本文属于 RL 驱动路线，但用 **第一视角深度**补齐了盲策略的短板；
- 同时做成 **无步态先验**，让动作在训练中涌现出来（对 A1 这种小平台很关键）。

二、第二类：Locomotion from Elevation Maps（基于高程图的视觉移动）  
我把这类方法看成“感知与控制解耦”的传统范式：先建高程图，再规划落脚点/轨迹，再控制执行。
- 拆分流程（高程图 → foothold 规划 → 低阶控制）：落脚点可用启发式阈值 [59-63]，也可用学习判别 [64-68]；还有 traversibility map [69-72] 这种变体。  
- 简化流程（高程图 → RL → 直接输出动作）：省掉部分规划环节（比如输出步长/步高 [8,73] 或关节角 [17,74-76]），但**核心风险仍然在高程图本身**。

这类方法最大的坑我觉得就两点：
- **噪声/漂移会把高程图带偏**（位姿估计误差、相机晃动、odometry 漂移）；
- 即使加入噪声训练 [8] 或不确定性估计 [53,77,11]，在踏脚石/缝隙这种精细落脚地形上依然容易失效。

与本文的关系：本文等于直接跳过“高程图中间表征”，做 **第一视角深度 → 端到端关节目标**，从根上躲开高程图脆弱性。

三、第三类：Locomotion from Egocentric Depth（基于第一视角深度的视觉移动）  
这是和本文最接近的方向：不建高程图，直接用第一视角深度指导动作。但此前工作通常存在“任务窄/不落地/不端到端”的问题：

| 文献 | 核心思路 | 场景 | 我理解的局限 |
| --- | --- | --- | --- |
| [52] | 深度图避障 | 平坦地形 | 只能避障，搞不定楼梯/缝隙 |
| [78] | 分层策略 + 深度图 | 仿真迷宫/悬崖 | 没上真机，场景单一 |
| [79] | 激光雷达扫描 + 零样本迁移 | 复杂地形 | 依赖激光雷达（成本高），也不是相机深度 |
| [80]（Yu et al.） | 深度图→高层动作（如跨缝隙指令） | 跨缝隙 | 非端到端，还要低阶控制器补齐 |
| [81]（Margolis et al.） | 深度→全身冲量控制→跳跃 | 跳跃跨缝隙 | 任务太窄，只会跳 |

与本文的核心差异（我理解的创新点）：
- **端到端输出关节目标**：深度 + 本体感知直接出 12 维目标，不靠“高层指令→低层控制”的中间层；
- **真机 + 多地形覆盖**：楼梯/缝隙/踏脚石/路缘都有实测；
- **硬件成本低**：单目深度 + 低算力平台可跑。

四、研究局限性（Discussion and Limitations）  
论文的限制我觉得写得挺实在，核心还是 sim2real：
- **仿真-真实鸿沟**：视觉/几何分布 mismatch 时策略会崩；当前缓解方式更像“把失败场景加回去重训”，属于被动适配；
- **相机依赖**：遮挡、雨水、灰尘会直接打到输入；
- **记忆长度有限**：GRU 截断训练带来短期记忆上限，超长楼梯可能吃亏；
- **算力边界**：复杂动态环境下实时性可能是瓶颈。

总结：本文在领域中的定位  
我把它归纳成一句话：**用低成本第一视角深度，把四足视觉运动从“高程图 pipeline”推向“端到端控制”**，并且在小平台上给出可落地的实验闭环。
