# 智载千古：AI赋能考古研究的探索与实践

在这个数字化浪潮席卷全球的时代，古老的文明遗存正通过前沿技术的触角焕发出全新的生命力。我们的创赛项目**智载千古**（Intelligent Codex of Treasures）便是在这样的背景下应运而生。本项目致力于通过**人工智能技术**赋能考古研究，实现从良渚到世界的文明点亮，探索**中华文明探源工程**的数字化路径。凭借深厚的技术积淀与跨学科的创新应用，项目在 2024 年"建行杯"中国国际大学生创新大赛中脱颖而出，最终荣获**中国国际大学生创新大赛（2024）国赛铜奖**。

### 文明探源与时代使命

考古工作不仅是发现过去，更是为了通过实证来理解历史、传承价值。项目立足于**国家文化自信**的战略高度，旨在通过 **AI 技术**还原历史真相，存续文化基因。在研究过程中，我们深刻认识到考古学对于增强民族凝聚力和筑梦中华民族复兴的重要意义。因此，**智载千古**不仅仅是一个技术工具的集合，它更是一次跨越千年的科技对话，试图向世界展示中华文明的灿烂成就。

![智载千古项目概览](/img/archaeological-reports/image1.png)

### 跨学科深度协作与名师引领

本项目的诞生离不开顶尖科研力量的支持。在**良渚古城**的发现者**刘斌老师**的引领下，项目团队深入良渚遗址一线，推动考古研究从简单的遗迹发现走向深度的价值挖掘。

同时，项目依托**浙江大学计算机辅助设计与图形学（CAD&CG）国家重点实验室**，以及**艺术与考古图像数据实验室**的强大平台。这种"**艺术+科技**"的跨学科协作模式，为解决考古中的实际难题提供了坚实的技术保障。通过将**潘云鹤院士**等顶尖学者的学术成果应用于文化遗产保护，我们成功打破了学科壁垒，开启了 **AI+考古**的新范式。

### 传统考古的现实痛点与行业挑战

尽管考古学科在不断发展，但传统考古研究方法在面对**海量数据**时依然存在明显的瓶颈。在实际的田野调查与报告整理中，考古研究人员常常面临**数据零散、质量参差不齐以及分析难度大**等痛点。

![传统考古痛点分析](/img/archaeological-reports/image2.png)

首先，考古数据的记录和处理在很大程度上依然依赖**人工**。无论是器物线图的绘制、拓片的数字化整理，还是各类考古报告的编写，其**自动化程度极低**。这种低效率的作业模式不仅耗费了大量研究人员的时间，也使得大量珍贵的考古材料长期处于**碎片化状态**，难以进行大规模的横向对比和深度分析。其次，**数据标准的不统一**导致跨遗址、跨区域的联合研究极度困难。面对即将展开的**第四次全国文物普查**，传统的作业方式已难以满足现代考古对精准度和效率的需求。

### 智载千古：新一代科技考古一体化平台

为了应对上述挑战，我们开发了**智载千古**——下一代科技考古一体化平台。项目集成了 **YOLO 目标检测**、**大型语言模型（LLM）**、**文字识别（OCR）**等多种先进技术，旨在解决传统考古中**数据处理慢、分析难**的核心问题。

平台通过**智能提取器物特征**、**自动化分析墓葬数据**以及**结构化考古报告**，大幅提升了研究效率。例如，通过**计算机视觉模型**，我们可以快速从复杂的考古报告中精准检测并分割出器物线图，并结合**版面分析算法**实现自动化的图注匹配。这一平台的应用，不仅能够帮助研究人员从繁琐的机械劳动中解脱出来，更能通过**数据挖掘**发现隐藏在历史细节背后的社会网络关系和文化变迁规律。

![架构](/img/archaeological-reports/image3.png)

## 核心技术实现

我主要负责基于**深度学习**的**线图自动化提取与结构化处理**。这是一个典型的**多模态任务**，不仅需要精确的**计算机视觉定位**，还需要逻辑严密的**后处理算法**将视觉坐标与文本语义进行精准匹配。为了实现这一目标，我们构建了一套完整的技术流水线，涵盖了从原始 **PDF 文档转换**到最终**器物卡片生成**的全部流程。

### 技术架构与全流程设计

项目的底层工程结构遵循**模块化原则**设计，以确保**海量考古报告处理**时的稳定性。整个系统被划分为 **PDF 转换模块**、**OCR 文本识别模块**、**YOLO 视觉检测模块**、以及**基于大语言模型的语义提取模块**。

```python
# 项目核心目录结构逻辑
# D:\PADDLEOCR\PROJECT
# ├─source           # 原始考古报告 PDF 存放地
# ├─picture          # PDF 转图片后的中间产物
# ├─ocr_result       # PaddleOCR 生成的坐标与文本记录
# ├─llm_result       # DeepSeek API 处理后的结构化 Excel 表格
# └─utils            # 图像预处理与坐标匹配工具库

```

处理流程的首要环节是将数百页的考古报告（如《**良渚遗址群考古报告之四：庙前**》）转化为**高分辨率的图像**。由于 **OCR** 和 **YOLO** 对图像像素密度的敏感性，我采用了 `PyMuPDF`（fitz）库，并设定了 **2.0** 的水平与垂直缩放因子，以保证在后续处理中即使是微小的器物序号也能清晰可辨。

```python
import fitz

def pdf2img(pdf_path, img_dir):
    doc = fitz.open(pdf_path)
    for page in doc:
        # 设置缩放因子以提升 OCR 识别精度
        zoom_x = 2.0
        zoom_y = 2.0
        mat = fitz.Matrix(zoom_x, zoom_y)
        pix = page.get_pixmap(matrix=mat)
        pix.save(r"{}page-{}.jpg".format(img_dir, page.number))

if __name__ == '__main__':
    pdf2img("./source/庙前.pdf", "./picture/")

```

> [图片占位符：引用《线图提取.pdf》第 2 页，展示 PDF 转换后的原图与初步分割效果]

### 视觉中枢：基于 YOLO 的多目标检测与空间匹配

这是我投入精力最多的部分。考古报告的版面**极其复杂**，一页往往包含**数十个器物线图**，且图注和序号的排布没有统一规律。传统的 **OCR** 无法理解"哪个序号对应哪个器物"，我选择通过 **YOLOv8**（后升级至 **YOLOv10**）来建立**空间索引**。

我定义了**五类核心标注对象**：线图整体（zhengti）、单个器物（qiwu）、序号框（xuhao）、图注（tuzhu）以及墓葬元素（muzang）。其中，"**整体框**"的设计是解决版面分析难题的关键。通过先定位"**图注单元**"，再在该单元内寻找器物与序号，有效避免了**跨区域的命名污染**。

在后处理脚本中，我实现了一套基于 **IOU（交并比）**的空间归属算法。系统会计算每一个"序号框"与"器物框"的重合度，当 **IOU 超过 0.5** 时，系统自动建立二者的逻辑链接。这一逻辑不仅解决了"谁是谁"的问题，更为后续的**自动化命名**打下了基础。

```bash
# 部署 YOLO 模型进行全自动预测
yolo predict model=weights/best.pt source=./picture save_txt=True hide_labels=False

```

![YOLO 检测效果展示](/img/archaeological-reports/image5.png)

### 语义大脑：大模型驱动的结构化卡片生成

在视觉信息提取完毕后，如何将 **OCR** 识别出的零散文字转化为专业的**考古器物卡片**是另一个难点。考古报告中的文字描述**极其密集且具有高度的专业性**，简单的正则匹配无法处理复杂的语义关系。

通过**分段处理文本块（Chunks）**，系统能够自动提取**遗迹号、尺寸、颜色、器型细分类、材质以及完整程度**等**十余个表头字段**。针对 OCR 产生的冗余信息（如页眉、页码），我设计了**基于位置坐标的过滤机制**，大幅提升了 **LLM** 的处理效率和准确率。

### 极客精神：在工程实践中的迭代与反思

没有任何一个 **AI 模型**是完美的。在处理《**庙前**》和《**文家山**》等真实考古数据时，我遇到了"**指鹿为马**"（OCR 错误识别数字）、"**眼盲**"（YOLO 漏检细小序号）等典型工程问题。

针对图像质量导致的识别率低，我回溯到了**传统计算机视觉**领域。参考学长经验，我构建了一套**图像预处理流水线**：先进行**灰度化与中值滤波去噪**，再利用 **Otsu 自适应阈值算法**进行二值化，最后通过 **Canny 边缘检测**和 **CLAHE 对比度增强**来突出文字轮廓。这种"**传统 CV 预处理 + 深度学习识别**"的组合拳，显著提升了在模糊扫描件上的表现。

同时，我完成了从 **YOLOv8** 到 **YOLOv10** 的架构迁移。在训练过程中，我针对识别率较低的"**玉管**"等细长器物增加了训练集比重，并使用 **YOLOv10m** 和 **YOLOv10x** 不同的预训练模型进行对比实验。最终，全流程的**自动化命名成功率大幅提升**，将原本需要**数天**的人工整理工作缩短到了**小时级别**。

