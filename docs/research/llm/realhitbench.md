# 超越扁平：RealHiTBench 如何为大语言模型（LLM）的表格处理能力设立新标杆

随着大语言模型（LLMs）的飞速发展，它们在文本生成、摘要和对话方面的能力已经令人印象深刻。然而，当我们把目光从非结构化的文本转向结构化的表格数据时，一个更深层次的挑战浮现了：LLMs 真的能“理解”现实世界中那些复杂的、多层次的表格吗？

《RealHiTBench: A Comprehensive Realistic Hierarchical Table Benchmark》里，我们不仅指出了当前评测基准的局限性，还通过构建一个极具挑战性的新基准，揭示了 SOTA 模型在真实复杂表格分析任务中的能力边界。

## 问题的根源：为什么我们需要一个新的表格评测基准？

长期以来，许多流行的表格问答（TableQA）评测基准，比如 TAT-QA 和 TableBench，大多依赖于结构简单的“扁平表格” (flat tables)。这类表格中，每一行代表一个记录，每一列代表一个属性，结构清晰明了。

但在经济、科学、社会等多个领域的实际应用中，表格的结构远比这复杂。为了在二维空间内呈现多维信息，人们创造了大量包含层级结构的表格。虽然已有一些工作（比如 HiTab）开始关注层级表格，但它们往往存在领域局限、格式有损（比如预处理成 JSON 破坏了原始结构）、或层级结构过于简单等问题。

这种评测基准与现实应用之间的脱节，让我们无法准确评估 LLM 在处理真实世界复杂表格时的真正实力。而 RealHiTBench，正是我们为了填补这一空白所开发的工具。

## RealHiTBench 的核心创新：定义并挑战“真·复杂”

RealHiTBench 的核心贡献，在于我们对“复杂表格结构”的系统性定义和应用。它不只是数据的堆砌，更是对复杂性的深刻解构。在论文中，我们定义了五种典型的复杂结构，大家可以通过论文中的核心示例图（Figure 1）直观理解：

1. **层级列头 (Hierarchical Column Header)**：这可能是最常见的复杂结构。通过单元格合并，列头被组织成一个树状层级。比如在 Figure 1 中，“Average hours per day” 这个一级表头下，又分出了“Both full time”和“Mother part time & Father full time”两个二级表头，每个二级表头下还细分了“Mothers”和“Fathers”。这种结构要求模型必须理解列与列之间的从属关系。

2. **层级行头 (Hierarchical Row Header)**：与列头类似，行头也能通过缩进或多列分组来表示层级。在 Figure 1 中，“Household”这一项下面，通过缩进展示了“Housework”“Food”“Lawn”等多个子项，清晰表达了它们之间的包含关系。

3. **嵌套子表 (Nested Sub-Tables)**：有时，一个大表内部会由横跨整个表格宽度的特殊行（通常是标题行）分割成多个语义上独立的子区域。Figure 1 中，“Children under 18”“Children under 6”等橙色背景的行，就将整个表格划分成了针对不同年龄段儿童的独立统计区域。模型需要理解，对“所有儿童”的提问，可能并不意味着对所有数字进行简单加总。

4. **隐式多表连接 (Implicit Multi-Table Join)**：这是一种非常巧妙且在现实中常见的设计。从表面看，它可能只是一个大表，但实际上它并列了多个结构完全相同的子表，目的是实现数据间的直观对比。Figure 1 的左右两侧分别展示了“Children under 18”和“Children 7-12”等不同群组的数据，它们的列结构完全一致，这本身就蕴含了对比的语义。

### 任务设计：不止于查找，更考验深度理解

为了全面评估模型的能力，我们为 RealHiTBench 设计了五大类、包含多个子类的复杂任务：

* **事实核查 (Fact Checking)**：包括需要整合多处信息进行验证的“多跳核查”，以及需要基于表格信息进行逻辑推理的“推理核查”。
* **数值推理 (Numerical Reasoning)**：涵盖了计数、排序、比较和复杂计算等多种需要数学能力的任务。这要求模型不仅要定位数据，还要正确执行数学运算。
* **数据分析 (Data Analysis)**：这是更高阶的任务，要求模型进行初步分析、总结、预测，甚至探索性分析和异常检测。比如，模型需要根据表格数据总结趋势或发现异常值。
* **图表生成 (Chart Generation)**：要求模型根据数据生成可执行的代码来绘制图表，比如条形图、折线图等。这直接考验了模型将结构化数据转换为可视化代码的能力。
* **结构理解 (Structure Comprehending)**：这是我们专为复杂表格设计的创新任务类型。我们会通过修改（比如交换）表格的某些结构部分，然后对新旧两个表格问同一个问题，以此评测模型是否真正理解结构变化对答案的决定性影响。

## TreeThinker：从“看”表格到“理解”表格结构

在 RealHiTBench 中提出评测难题后，我们还探索了解决思路，设计了一个名为 **TreeThinker** 的理解增强流水线。这个方案的核心思想很直观：在让 LLM 直接回答问题前，先引导它把表格的层级结构显式地解析成“树”的形式，从而将隐式的结构信息转化为显式的、可供模型直接利用的知识。

### 第一步：树生成 (Tree Generation) - 绘制“结构蓝图”

TreeThinker 首先会引导模型对表格进行结构化的自我解析，具体分为两步：

1. **编码与解释**：我们引导模型将每个表头（无论是行还是列）编码为一个包含四元素的元组 `T=(t1, t2, t3, t4)`。这个元组能精确描述表头的全部信息：`t1` 代表类型（行/列）和层级，`t2` 和 `t3` 代表它在表格中的起始和结束位置，`t4` 则是单元格的具体内容。比如 `(R0, 1, 2, City)` 就表示这是一个0级行头，从第1行跨越到第2行，内容是“City”。

2. **构建层级树**：得到所有表头的元组列表后，模型会根据它们的层级和跨越范围（起始、结束位置）确定父子关系。如果一个低层级的表头，其位置范围被一个高层级表头完全包含，那么它们之间就构成了父子关系。通过这种方式，原本扁平的表头列表会被组织成等级分明的“表头树”。

### 第二步：基于树的推理 (Tree-based Reasoning) - 精准定位与思考

有了这张“结构蓝图”，推理过程会变得更精准高效，具体分为三步：

1. **分解与对齐**：模型首先会将用户的问题分解成一组关键词 `K=[k1, k2, ..., km]`。之后，它会执行对齐操作，计算每个关键词 `k` 与表头树中每个节点 `T` 的匹配度 (`Align_LM(T,k)`)。

2. **定位子表**：我们会设定一个特定阈值，只有匹配度超过阈值的表头节点才会被选中，形成一个与问题高度相关的“关键词-表头子树” (`H'`)。这个子树会指导模型从原始表格中精确抽取出回答问题所需的核心信息。

3. **迭代求精**：最后，TreeThinker 还采用了一种类似 ReAct 的多轮“思考-行动-结果”精炼策略，对抽出的信息进行迭代处理，最终生成答案。

从实验结果来看，TreeThinker 的效果很显著。比如，在使用该方法后，GPT-4o 在图表生成任务上的 PASS@1 指标提升了惊人的 134.7%。这也印证了我们的判断：显式地理解表格结构，是解锁 LLM 更高阶表格处理能力的关键。

## 实验结果揭示的真相

我们用 RealHiTBench 对 25 个当前主流的 LLM 和 MLLM 进行了全面评测，得出的结果很值得思考：

* **普遍表现不佳**：即便是像 GPT-4o 这样的顶级模型，在多数任务上的表现也远未达到理想状态，精确匹配率（EM）最高没超过 70。这说明 RealHiTBench 确实是一个极具挑战性的基准，也印证了我们构建它的价值。
* **文本优于图像**：在处理复杂表格结构时，基于文本（尤其是 LaTeX 格式）的输入，平均表现要优于图像（PNG）输入。我们推测，这可能是因为文本格式能更无损地保留精细的结构信息。
* **模型越大，推理越强**：拥有 671B MoE 架构的 DeepSeek-R1 在所有模型中表现最出色。这在一定程度上表明，强大的通用推理能力，对于攻克复杂表格结构至关重要。

## 结语与展望
这个工作给我最大的启发是：我们对 LLM 的评估，需要从“通用能力”转向“特定领域的深度能力”。在表格分析领域，这就意味着我们必须正视并量化“结构复杂性”这一核心挑战。