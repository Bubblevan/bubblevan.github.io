---
id: rl-chapter-8
title: 第8章 价值函数方法
sidebar_label: 第8章
---

# Value Function Methods

## Value representation: From table to function

假设存在 $n$ 个状态 $\{s_i\}_{i=1}^n$，其状态值为 $\{v_{\pi}(s_i)\}_{i=1}^n$，其中 $\pi$ 是给定的策略。用 $\{\hat{v}(s_i)\}_{i=1}^n$ 表示真实状态值的估计值。若采用表格法，可将估计值存储在下表中。该表格可作为数组或向量存储在内存中，要检索或更新某个值，直接读取或改写表格中对应的条目即可。

| 状态（State） | $s_1$ | $s_2$ | $\cdots$ | $s_n$ |
|-------------|-------|-------|---------|-------|
| 估计值（Estimated value） | $\hat{v}(s_1)$ | $\hat{v}(s_2)$ | $\cdots$ | $\hat{v}(s_n)$ |

接下来我们将说明，上述表格中的值可通过一个函数来近似。具体而言，在下图

<div style={{textAlign: 'center'}}>
  ![](/img/rl/f8-1.png)
</div>

中，$\{(s_i, \hat{v}(s_i))\}_{i=1}^n$ 被表示为 $n$ 个点，这些点可通过一条曲线进行拟合或近似。最简单的曲线是直线，其表达式可写为：

$$
\begin{aligned}
\hat{v}(s, w) = as + b = \underbrace{[s, 1]}_{\phi^T (s)} \underbrace{\begin{bmatrix} a \\ b \end{bmatrix}}_{w} = \phi^T (s)w \tag{8.1}
\end{aligned}
$$

其中，$\hat{v}(s, w)$ 是用于近似 $v_{\pi}(s)$ 的函数，由状态 $s$ 和参数向量 $w \in \mathbb{R}^2$ 共同决定，有时也记为 $\hat{v}_w(s)$；$\phi(s) \in \mathbb{R}^2$ 被称为状态 $s$ 的特征向量。

表格法与函数近似法的第一个显著区别，体现在值的检索方式和更新方式上。

- **值的检索方式**：当值以表格形式存储时，检索某个值只需直接读取表格中对应的条目；而当值以函数形式表示时，检索过程会稍复杂 —— 需将状态索引 $s$ 输入函数并计算函数值（见图 8.3）。以式（8.1）的示例为例，首先需计算特征向量 $\phi(s)$，再计算 $\phi^T(s)w$；若函数为人工神经网络，则需从输入到输出进行一次前向传播。

由于状态值的检索方式不同，函数近似法在存储效率上更具优势：表格法需存储 $n$ 个值，而函数近似法只需存储一个低维参数向量 $w$，因此存储效率可显著提升。但这种优势并非无代价 —— 函数可能无法准确表示所有状态值。例如，图 8.2 中的点无法用一条直线精确拟合，这也是该方法被称为 "近似法" 的原因。从本质上讲，用低维向量表示高维数据集时，必然会损失部分信息。因此，函数近似法是通过牺牲精度来换取存储效率的。

- **值的更新方式**：当值以表格形式存储时，更新某个值只需直接改写表格中对应的条目；而当值以函数形式表示时，更新方式完全不同 —— 必须通过更新参数 $w$ 来间接改变值。关于如何更新 $w$ 以得到最优状态值，后续会详细阐述。

得益于状态值的更新方式，函数近似法还具备另一项优势：泛化能力强于表格法。原因如下：采用表格法时，仅当某状态在一个回合中被访问时，其值才能被更新，未被访问状态的值无法更新；而采用函数近似法时，更新某状态值需先更新参数 $w$，且 $w$ 的更新会同时影响其他未被访问状态的值。因此，单个状态的经验样本可推广到其他状态，助力其值的估计。

上述分析可通过下图进一步说明（图中包含 3 个状态 $\{s_1, s_2, s_3\}$）：假设我们有状态 $s_3$ 的经验样本，并希望更新 $\hat{v}(s_3)$。

- **表格法**：如图 (a) 所示，仅能更新 $\hat{v}(s_3)$，$\hat{v}(s_1)$ 和 $\hat{v}(s_2)$ 保持不变；
- **函数近似法**：如图 (b) 所示，通过更新 $w$ 不仅能更新 $\hat{v}(s_3)$，还会改变 $\hat{v}(s_1)$ 和 $\hat{v}(s_2)$ 的值。

因此，状态 $s_3$ 的经验样本可助力其邻近状态值的更新。

<div style={{textAlign: 'center'}}>
  ![](/img/rl/f8-2.png)
</div>

我们可使用比直线近似能力更强的复杂函数，例如二阶多项式：

$$
\begin{aligned}
\hat{v}(s, w) = as^2 + bs + c = \underbrace{[s^2, s, 1]}_{\phi^T (s)} \underbrace{\begin{bmatrix} a \\ b \\ c \end{bmatrix}}_{w} = \phi^T (s)w \tag{8.2}
\end{aligned}
$$

还可使用更高阶的多项式曲线拟合这些点：曲线阶数越高，近似精度可能越高，但参数向量的维度也会随之增加，进而需要更多的存储资源和计算资源。

需注意的是，无论是式（8.1）还是式（8.2）中的 $\hat{v}(s, w)$，其关于 $w$ 都是线性的（尽管关于 $s$ 可能是非线性的），这类方法被称为**线性函数近似法**，是最简单的函数近似法。

要实现线性函数近似，需选择合适的特征向量 $\phi(s)$—— 例如，需判断用一阶直线还是二阶曲线拟合这些点。选择合适的特征向量并非易事，它需要依赖对任务的先验知识：对任务的理解越深入，越能选择出更优的特征向量。例如，若已知图 8.2 中的点大致分布在一条直线上，便可采用直线拟合；但在实际场景中，这类先验知识通常是未知的。若缺乏任何先验知识，一种常用的解决方案是采用人工神经网络作为非线性函数近似器。

另一重要问题是如何寻找最优参数向量：若已知 $\{v_{\pi}(s_i)\}_{i=1}^n$，则该问题可转化为最小二乘问题。通过优化以下目标函数，可得到最优参数：

$$
\begin{aligned}
J_1 &= \sum_{i=1}^n \left( \hat{v}(s_i, w) - v_{\pi}(s_i) \right)^2 = \sum_{i=1}^n \left( \phi^T(s_i)w - v_{\pi}(s_i) \right)^2 \\
&= \left\| \begin{bmatrix} \phi^T(s_1) \\ \vdots \\ \phi^T(s_n) \end{bmatrix} w - \begin{bmatrix} v_{\pi}(s_1) \\ \vdots \\ v_{\pi}(s_n) \end{bmatrix} \right\|_2^2 = \|\Phi w - v_{\pi}\|_2^2
\end{aligned}
$$

其中，$\Phi \triangleq \begin{bmatrix} \phi^T(s_1) \\ \vdots \\ \phi^T(s_n) \end{bmatrix} \in \mathbb{R}^{n \times 2}, \quad v_{\pi} \triangleq \begin{bmatrix} v_{\pi}(s_1) \\ \vdots \\ v_{\pi}(s_n) \end{bmatrix} \in \mathbb{R}^n$

可验证，该最小二乘问题的最优解为：$w^* = (\Phi^T \Phi)^{-1} \Phi v_{\pi}$

## TD learning of state values based on function approximation

## 