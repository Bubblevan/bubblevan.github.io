---
id: rl-chapter-11
title: 第11章 PPO
sidebar_label: 第11章
---

# Proximal Policy Optimization
感觉无论是王树森老师还是赵世钰老师都没有讲到PPO、SFT、DPO、GRPO这些算法，还得额外找其他地方来学习。再加上学习强化学习打基础主要原因是看Falcon的Methodology大败而归，因此需要额外补一些其他的内容：

- [小鱼儿at青岛](https://www.bilibili.com/video/BV1qrbrzqEwL/?spm_id_from=333.337.search-card.all.click&vd_source=2c8a191726cb019c16737188a8d0b3ac)
- [五道口纳什](https://www.bilibili.com/video/BV1pXA5eyEEg/?spm_id_from=333.337.search-card.all.click&vd_source=2c8a191726cb019c16737188a8d0b3ac)

这两位B站博主可以很好的入门强化学习上面所提到的RL算法以及VeRL框架之类的，但是Auxiliary Tasks in RL(Jaderberg et al. (2016) "Reinforcement Learning with Unsupervised Auxiliary Tasks")这些可能还要我自己再找文章看。
