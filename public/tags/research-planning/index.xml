<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bubblevan – Research-Planning</title>
    <link>http://localhost:1313/tags/research-planning/</link>
    <description>Recent content in Research-Planning on Bubblevan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    
	  <atom:link href="http://localhost:1313/tags/research-planning/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>社会意识的导航模型</title>
      <link>http://localhost:1313/blog/2025/2025-11-29-social-nav/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/blog/2025/2025-11-29-social-nav/</guid>
      <description>
        
        
        &lt;p&gt;起因是在小红书上刷到了这一篇2025年11月的新文章&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/blog/2025/social-nav.jpg&#34; alt=&#34;Social Navigation&#34;  loading=&#34;lazy&#34; /&gt;&lt;/p&gt;
&lt;p&gt;结果却搜到了 &lt;strong&gt;[ICRA 2025] From Cognition to Precognition: A Future-Aware Framework for Social Navigation&lt;/strong&gt;，于是误闯天家到了 &lt;a href=&#34;https://github.com/Shuijing725/awesome-robot-social-navigation&#34;target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Awesome Robot Social Navigation&lt;/a&gt; 的领域。&lt;/p&gt;
&lt;h2&gt;什么是 Social Navigation？&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;什么是-social-navigation&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#%e4%bb%80%e4%b9%88%e6%98%af-social-navigation&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Social Navigation（社会导航）&lt;/strong&gt; 的核心思想是 &lt;strong&gt;&amp;ldquo;以人为本&amp;rdquo;&lt;/strong&gt;。它要求机器人不仅仅把人类当作需要避开的障碍物，而是能够理解并尊重人类的社会规范与个人空间，最终实现&lt;strong&gt;自然、和谐、无感知压迫&lt;/strong&gt;的共同空间使用。例如，在走廊中与人迎面相遇时，机器人会像人一样靠右行驶；当需要穿过一群人时，它会寻找合适的时机和路径，而不是生硬地&amp;quot;切开&amp;quot;人群。&lt;/p&gt;
&lt;h2&gt;技术对比：Social Navigation vs LOVON vs VLN&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;技术对比social-navigation-vs-lovon-vs-vln&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#%e6%8a%80%e6%9c%af%e5%af%b9%e6%af%94social-navigation-vs-lovon-vs-vln&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;特性维度&lt;/th&gt;
          &lt;th&gt;Social Navigation (社会导航)&lt;/th&gt;
          &lt;th&gt;LOVON (腿部开放词汇物体导航)&lt;/th&gt;
          &lt;th&gt;VLN (视觉语言导航)&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;核心目标&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;安全、舒适、符合社会规范地在人类共享空间中导航&lt;/td&gt;
          &lt;td&gt;在开放世界中，根据物体名称，自主搜索并导航到指定物体&lt;/td&gt;
          &lt;td&gt;根据自然语言指令，在环境中执行导航任务 (如&amp;quot;去厨房拿杯水&amp;quot;)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;环境特点&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;动态、拥挤的人类环境，充满不确定性&lt;/td&gt;
          &lt;td&gt;非结构化的开放环境，地形复杂，目标物体可能被遮挡或距离遥远&lt;/td&gt;
          &lt;td&gt;通常基于仿真器（如Habitat, AI2-THOR），环境可以是静态的，也引入动态人类&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;关键输入&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;人类的位置、运动轨迹、群体行为、社会规范&lt;/td&gt;
          &lt;td&gt;目标物体的文本名称 (如 &amp;ldquo;chair&amp;rdquo;)、机器人视觉传感器数据&lt;/td&gt;
          &lt;td&gt;详尽的自然语言指令、机器人视觉传感器数据&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;技术侧重点&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;行人轨迹预测、社交力模型、强化学习策略、舒适度与安全性评估&lt;/td&gt;
          &lt;td&gt;开放词汇目标检测、大语言模型任务分解、腿部机器人运动控制、抗运动模糊&lt;/td&gt;
          &lt;td&gt;视觉-语言对齐、指令理解、跨模态推理、路径规划&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;典型输出/动作&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;避让、保持社交距离、绕行、调整速度、非语言沟通&lt;/td&gt;
          &lt;td&gt;朝向目标物体的运动控制命令 (如速度、方向)，处理复杂地形&lt;/td&gt;
          &lt;td&gt;导航动作 (如&amp;quot;左转&amp;quot;、&amp;ldquo;前进1米&amp;rdquo;、&amp;ldquo;停止&amp;rdquo;)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;核心挑战&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;对人类意图的预测、复杂社会规则的建模与量化、安全性、舒适感&lt;/td&gt;
          &lt;td&gt;长时序任务规划、动态模糊下的稳定感知、复杂地形下的稳定移动、开放词汇识别泛化能力&lt;/td&gt;
          &lt;td&gt;指令与环境的关联、未知环境泛化、长指令理解、跨模态表示学习&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;学术社区与行业洞察&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;学术社区与行业洞察&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#%e5%ad%a6%e6%9c%af%e7%a4%be%e5%8c%ba%e4%b8%8e%e8%a1%8c%e4%b8%9a%e6%b4%9e%e5%af%9f&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;然后去&lt;a href=&#34;http://xhslink.com/o/6M94ZS8vHHm&#34;target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;学术社区（迫真）&lt;/a&gt;上搜索了一下，这里 &lt;strong&gt;seven17&lt;/strong&gt; 这位大佬也在2025年11月16-17给出了自己作为人形公司 &lt;strong&gt;SLAM 面试官&lt;/strong&gt;对业界人形机器人在研究的算法的一些经验，非常有参考意义。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;有一说一小红书真的比很多像是CSDN之类的更好的学术交流平台&lt;/p&gt;

&lt;/blockquote&gt;
&lt;p&gt;我就很赞同这里在小红书的某个 Ask Me Anything 上看到的&lt;strong&gt;港科广的梁老师&lt;/strong&gt;的话：&lt;/p&gt;
&lt;div style={{display: &#39;flex&#39;, justifyContent: &#39;space-between&#39;, gap: &#39;10px&#39;}}&gt;
  &lt;div style={{flex: 1}}&gt;
    &lt;img src=&#34;http://localhost:1313/blog/2025/gkg-liang1.jpg&#34; alt=&#34;港科广梁老师观点1&#34; style={{width: &#39;100%&#39;}} /&gt;
  &lt;/div&gt;
  &lt;div style={{flex: 1}}&gt;
    &lt;img src=&#34;http://localhost:1313/blog/2025/gkg-liang2.jpg&#34; alt=&#34;港科广梁老师观点2&#34; style={{width: &#39;100%&#39;}} /&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2&gt;相关竞赛与研讨会&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;相关竞赛与研讨会&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#%e7%9b%b8%e5%85%b3%e7%ab%9e%e8%b5%9b%e4%b8%8e%e7%a0%94%e8%ae%a8%e4%bc%9a&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;活动名称&lt;/th&gt;
          &lt;th&gt;主要关联会议&lt;/th&gt;
          &lt;th&gt;活动形式&lt;/th&gt;
          &lt;th&gt;核心侧重点&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;RoboSense机器感知挑战赛&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;IROS 2025 (官方认证竞赛)&lt;/td&gt;
          &lt;td&gt;竞赛&lt;/td&gt;
          &lt;td&gt;在动态人群环境中，使机器人的导航行为符合人类的社会规范。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Advances in Social Robot Navigation研讨会&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;ICRA 2025&lt;/td&gt;
          &lt;td&gt;研讨会&lt;/td&gt;
          &lt;td&gt;探讨社交机器人导航在规划、人机交互等领域的最新进展，并包含基准测试挑战。&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;RoboSense 挑战赛&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;robosense-挑战赛&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#robosense-%e6%8c%91%e6%88%98%e8%b5%9b&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;RoboSense挑战赛&lt;/strong&gt; 是 &lt;strong&gt;IROS 2025&lt;/strong&gt; 的官方认证竞赛，它设置了专门的&lt;strong&gt;社交导航赛道&lt;/strong&gt;，旨在解决机器人在真实动态环境中的导航问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;任务目标：&lt;/strong&gt; 参赛者需要开发一个基于 &lt;strong&gt;RGB-D 输入&lt;/strong&gt;的移动机器人导航模型。该模型的核心任务是让机器人在&lt;strong&gt;不影响周围人类行为&lt;/strong&gt;的前提下完成导航，并使其行为符合人类的社会规范，例如主动避让、保持合适的社交距离等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;挑战与评测：&lt;/strong&gt; 除了衡量导航成功率和路径效率，比赛还特别引入了&lt;strong&gt;个人空间合规性（PSC）&lt;strong&gt;和&lt;/strong&gt;人机碰撞次数（H-Coll）&lt;strong&gt;等指标，专门用于量化机器人行为的&lt;/strong&gt;&amp;ldquo;社交友好度&amp;rdquo;&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;前沿技术：&lt;/strong&gt; 该赛道推荐的基线模型（Baseline）是 &lt;strong&gt;Falcon&lt;/strong&gt;，这是一个由&lt;strong&gt;港科广和港科大联合提出&lt;/strong&gt;的新算法，它通过将&lt;strong&gt;轨迹预测算法融入强化学习框架&lt;/strong&gt;，让机器人能够预测行人未来的移动路径，从而实现&lt;strong&gt;更超前、更安全的规划&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ICRA 2025 研讨会&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;icra-2025-研讨会&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#icra-2025-%e7%a0%94%e8%ae%a8%e4%bc%9a&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;除了竞争激烈的比赛，&lt;strong&gt;ICRA 的&amp;quot;Advances in Social Robot Navigation&amp;quot;研讨会&lt;/strong&gt;则是深入了解该领域学术研究和前沿发展的绝佳平台。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;活动形式：&lt;/strong&gt; 这是一个学术研讨会，会邀请领域内的专家进行讲座和专题讨论。同时，它也主办 &lt;strong&gt;Arena 4.0 挑战赛&lt;/strong&gt;，旨在为不同的社交导航策略建立基准和评测体系。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;核心议题：&lt;/strong&gt; 研讨会关注如何使机器人的导航行为&lt;strong&gt;更易于理解、更符合社交场景&lt;/strong&gt;。探讨的技术方向包括运动任务规划、&lt;strong&gt;基础模型的应用&lt;/strong&gt;、人机交互策略等。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;我的研究计划&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;我的研究计划&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#%e6%88%91%e7%9a%84%e7%a0%94%e7%a9%b6%e8%ae%a1%e5%88%92&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;我打算接下来的核心往 &lt;strong&gt;Social Navigation&lt;/strong&gt; 上面靠，这里很符合&lt;strong&gt;以人为本的设计特点&lt;/strong&gt;，而 &lt;strong&gt;LOVON&lt;/strong&gt; 也确实面临这一困境。也如梁老师所言，这是个&lt;strong&gt;容易入门具身的领域&lt;/strong&gt;。可惜这个比赛在这个时候已经结束了，下面计划的第一步是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;研读 Falcon 这个 baseline&lt;/strong&gt;（也就是上面提到的 ICRA 2025 中稿文章）&lt;/li&gt;
&lt;li&gt;使用 &lt;a href=&#34;https://robosense2025.github.io/track2&#34;target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Robosense&lt;/a&gt; 提供的 GitHub 代码和数据集去&lt;strong&gt;复现基线&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;参考排行榜的改进去思考参赛者解决的问题集中在哪里，又是如何进行的&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;相关资源&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;相关资源&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#%e7%9b%b8%e5%85%b3%e8%b5%84%e6%ba%90&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Resource&lt;/th&gt;
          &lt;th&gt;Link&lt;/th&gt;
          &lt;th&gt;Description&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;GitHub Repository&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/robosense2025/track2&#34;target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/robosense2025/track2&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Baseline code and setup instructions&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Dataset&lt;/td&gt;
          &lt;td&gt;HuggingFace Dataset&lt;/td&gt;
          &lt;td&gt;Dataset with training and test splits&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Baseline Model&lt;/td&gt;
          &lt;td&gt;Pre-Trained Model&lt;/td&gt;
          &lt;td&gt;Weights of the baseline model&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Registration&lt;/td&gt;
          &lt;td&gt;Google Form (Closed on August 15th)&lt;/td&gt;
          &lt;td&gt;Team registration for the challenge&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Evaluation Server&lt;/td&gt;
          &lt;td&gt;EvalAI Platform&lt;/td&gt;
          &lt;td&gt;Online evaluation platform&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;HuggingFace 上的热门研究&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;huggingface-上的热门研究&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#huggingface-%e4%b8%8a%e7%9a%84%e7%83%ad%e9%97%a8%e7%a0%94%e7%a9%b6&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在 huggingface 上按 trending 搜索 social navigation 的&lt;a href=&#34;https://huggingface.co/papers/trending?q=social&amp;#43;navigation&#34;target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;结果&lt;/a&gt;如下：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;论文标题&lt;/th&gt;
          &lt;th&gt;核心工作摘要&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;SACSoN&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;通过最小化机器人对行人行为的**&amp;ldquo;反事实扰动&amp;rdquo;&lt;strong&gt;，学习一种&lt;/strong&gt;不打扰人类的导航策略**。其关键在于使用大量真实人机交互数据进行训练。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Exploiting Proximity-Aware Tasks&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;提出&lt;strong&gt;邻近感知任务&lt;/strong&gt;，通过让策略理解即时和未来的碰撞危险，为强化学习导航策略注入&lt;strong&gt;常识性社交行为&lt;/strong&gt;。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;SELFI&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;提出一种&lt;strong&gt;在线自学习方法&lt;/strong&gt;，在预训练策略的基础上，利用在线模型无关的强化学习进行快速微调，使机器人能根据实际经验持续改进社交导航行为。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;SocialNav-SUB&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;引入了首个用于评估&lt;strong&gt;视觉语言模型（VLM）&lt;strong&gt;在社交导航场景中理解能力的基准，发现当前 VLM 在&lt;/strong&gt;空间、时空和社交推理&lt;/strong&gt;方面仍有明显不足。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;OLiVia-Nav&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;将&lt;strong&gt;视觉语言模型与在线终身学习框架&lt;/strong&gt;结合，通过独特的蒸馏方法让轻量级 VLM 直接理解社交和环境上下文，并规划符合社交规范的轨迹。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Habitat 3.0&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;推出了一个支持&lt;strong&gt;人、虚拟化身和机器人协同&lt;/strong&gt;的模拟平台，用于研究社交导航等协作任务，并提供了&lt;strong&gt;人类在环的基础设施&lt;/strong&gt;。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;GOAT&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;提出了一个&lt;strong&gt;通用导航系统&lt;/strong&gt;，能够处理多模态目标，并通过持续构建实例感知的语义记忆，实现&lt;strong&gt;终身学习和跨平台部署&lt;/strong&gt;。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;GRUtopia&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;构建了一个&lt;strong&gt;大规模的模拟交互式3D社会&lt;/strong&gt;，包含多样化的场景和由 &lt;strong&gt;LLM 驱动的虚拟角色&lt;/strong&gt;，用于支持社交移动导航等具身AI任务的训练与评估。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;RoboSense&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;提出了一个&lt;strong&gt;大规模的以自我为中心的多模态数据集&lt;/strong&gt;，专注于拥挤和非结构化环境中的感知与导航，为近场场景理解提供丰富标注。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Social NCE&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;通过&lt;strong&gt;对比学习&lt;/strong&gt;来提升运动表示的社交感知能力，显式地建模危险负样本，以此降低轨迹预测和行为克隆中的碰撞率。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;DriVLMe&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;探索了基于&lt;strong&gt;视频语言模型的自动驾驶智能体&lt;/strong&gt;，通过模拟环境和真实人类对话进行训练，旨在实现与人类的自然有效沟通。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;EPO&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;提出&lt;strong&gt;显式策略优化方法&lt;/strong&gt;，利用多轮强化学习和自我博弈来提升大语言模型在社交对话等任务中的战略推理能力。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;EmbodiedEval&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;提出了一个&lt;strong&gt;统一的、交互式的基准&lt;/strong&gt;，用于全面评估多模态大模型在具身任务（如导航、社交交互）中的能力。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;SocialEval&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;提出了一个评估&lt;strong&gt;大语言模型社交智能的双语基准&lt;/strong&gt;，通过叙事脚本从结果和过程两个维度评估模型的人际交往能力。&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;研究趋势分析&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;研究趋势分析&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#%e7%a0%94%e7%a9%b6%e8%b6%8b%e5%8a%bf%e5%88%86%e6%9e%90&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;从这些论文可以看出，社交导航领域的研究呈现出一些明显的趋势和重点方向：&lt;/p&gt;
&lt;h3&gt;1. 从&amp;quot;避障&amp;quot;到&amp;quot;避人&amp;quot;，再到&amp;quot;不扰人&amp;quot;&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;1-从避障到避人再到不扰人&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#1-%e4%bb%8e%e9%81%bf%e9%9a%9c%e5%88%b0%e9%81%bf%e4%ba%ba%e5%86%8d%e5%88%b0%e4%b8%8d%e6%89%b0%e4%ba%ba&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;像 &lt;strong&gt;SACSoN&lt;/strong&gt; 这样的工作，其目标已经超越了基础的安全避障，而是追求&lt;strong&gt;更高级的社交合规性&lt;/strong&gt;，希望机器人的存在和行为&lt;strong&gt;尽可能不改变人类的自然行为&lt;/strong&gt;。&lt;/p&gt;
&lt;h3&gt;2. 学习与规划的关键：预测与上下文理解&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;2-学习与规划的关键预测与上下文理解&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#2-%e5%ad%a6%e4%b9%a0%e4%b8%8e%e8%a7%84%e5%88%92%e7%9a%84%e5%85%b3%e9%94%ae%e9%a2%84%e6%b5%8b%e4%b8%8e%e4%b8%8a%e4%b8%8b%e6%96%87%e7%90%86%e8%a7%a3&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;许多研究致力于让机器人更好地&lt;strong&gt;预测未来&lt;/strong&gt;（如行人轨迹）和&lt;strong&gt;理解环境上下文&lt;/strong&gt;（如社交规则）。&lt;strong&gt;Exploiting Proximity-Aware Tasks&lt;/strong&gt; 和 &lt;strong&gt;Social NCE&lt;/strong&gt; 都是通过不同的方式让模型内化对潜在危险和社交规范的理解。&lt;/p&gt;
&lt;h3&gt;3. 基础模型与终身学习成为新风向&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;3-基础模型与终身学习成为新风向&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#3-%e5%9f%ba%e7%a1%80%e6%a8%a1%e5%9e%8b%e4%b8%8e%e7%bb%88%e8%ba%ab%e5%ad%a6%e4%b9%a0%e6%88%90%e4%b8%ba%e6%96%b0%e9%a3%8e%e5%90%91&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;OLiVia-Nav&lt;/strong&gt; 和 &lt;strong&gt;GOAT&lt;/strong&gt; 等论文清晰地展示了如何利用&lt;strong&gt;视觉语言模型（VLM）的先验知识&lt;/strong&gt;进行社交推理，并强调通过&lt;strong&gt;终身学习&lt;/strong&gt;使机器人能够适应不断变化的环境和新遇到的社交场景。&lt;/p&gt;
&lt;h3&gt;4. 对仿真、数据与评估的持续投入&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;4-对仿真数据与评估的持续投入&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#4-%e5%af%b9%e4%bb%bf%e7%9c%9f%e6%95%b0%e6%8d%ae%e4%b8%8e%e8%af%84%e4%bc%b0%e7%9a%84%e6%8c%81%e7%bb%ad%e6%8a%95%e5%85%a5&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;高质量的仿真平台（&lt;strong&gt;Habitat 3.0&lt;/strong&gt;, &lt;strong&gt;GRUtopia&lt;/strong&gt;）、大规模数据集（&lt;strong&gt;RoboSense&lt;/strong&gt;）和专门的评估基准（&lt;strong&gt;SocialNav-SUB&lt;/strong&gt;, &lt;strong&gt;EmbodiedEval&lt;/strong&gt;, &lt;strong&gt;SocialEval&lt;/strong&gt;）是推动领域发展的&lt;strong&gt;关键基础设施&lt;/strong&gt;，这些工作为训练、测试和公平比较不同算法提供了坚实基础。&lt;/p&gt;
&lt;h2&gt;核心挑战与思考&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;核心挑战与思考&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#%e6%a0%b8%e5%bf%83%e6%8c%91%e6%88%98%e4%b8%8e%e6%80%9d%e8%80%83&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;社会导航的终极目标&lt;/strong&gt;是实现&lt;strong&gt;安全、舒适、符合社会规范的人机共存与协作&lt;/strong&gt;。它关注的是导航行为的**&amp;ldquo;社交智能&amp;quot;和&amp;quot;礼仪&amp;rdquo;&lt;strong&gt;。相比之下，许多&lt;/strong&gt;视觉语言导航（VLN）&lt;strong&gt;或其变体（如 &lt;strong&gt;LOVON&lt;/strong&gt;）更侧重于理解指令、识别物体或地点，并完成具身的导航任务，其核心是&lt;/strong&gt;&amp;ldquo;完成任务&amp;quot;的准确性**。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最大的难点在于&lt;/strong&gt;，它需要让机器人理解并量化人类社会中那些&lt;strong&gt;不言自明、动态变化的社交潜规则&lt;/strong&gt;。例如，如何定义并计算**&amp;ldquo;个人空间&amp;rdquo;&lt;strong&gt;？如何判断什么样的路径是&lt;/strong&gt;&amp;ldquo;优雅&amp;quot;而非&amp;quot;冒犯&amp;quot;的**？这与开放词汇任务中要求模型识别未曾见过的物体类别（如 &lt;strong&gt;LOVON&lt;/strong&gt;）相比，是不同类型和层次的挑战。&lt;strong&gt;开放词汇扩展了机器人的&amp;quot;知识面&amp;rdquo;，而社会导航则是在塑造机器人的&amp;quot;情商&amp;quot;和行为方式&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;比如说 &lt;strong&gt;Track2&lt;/strong&gt; 的工作，核心任务是让机器人学会在充满动态行人的室内环境中（如办公楼、商场），实现&lt;strong&gt;安全、高效且符合社会规范的导航&lt;/strong&gt;。不仅要求机器人成功到达目的地（成功率 &lt;strong&gt;SR&lt;/strong&gt;），还要求其行为**&amp;ldquo;像个有礼貌的人&amp;rdquo;&lt;strong&gt;，比如主动保持舒适的社交距离（个人空间合规性 &lt;strong&gt;PSC&lt;/strong&gt;）、避免碰撞（人类碰撞率 &lt;strong&gt;H-Coll&lt;/strong&gt;），并规划出高效的路径（路径长度加权成功率 &lt;strong&gt;SPL&lt;/strong&gt;）。赛事提供的基线模型是基于 &lt;strong&gt;Falcon 框架&lt;/strong&gt;，它通过融入对&lt;/strong&gt;行人未来轨迹的预测**，来让机器人实现更具前瞻性的导航决策。&lt;/p&gt;
&lt;h2&gt;未来方向&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;未来方向&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#%e6%9c%aa%e6%9d%a5%e6%96%b9%e5%90%91&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;而在 &lt;a href=&#34;https://github.com/Shuijing725/awesome-robot-social-navigation&#34;target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;awesome系列&lt;/a&gt; 里，我们可以看到以下几个重要方向：&lt;/p&gt;
&lt;h3&gt;1. 融合基础模型&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;1-融合基础模型&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#1-%e8%9e%8d%e5%90%88%e5%9f%ba%e7%a1%80%e6%a8%a1%e5%9e%8b&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;这是一个明显的趋势。探索如何利用&lt;strong&gt;大型语言模型（LLM）&lt;strong&gt;和&lt;/strong&gt;视觉语言模型（VLM）&lt;/strong&gt;，让机器人能够理解和遵从复杂、抽象的社会规则（例如，**&amp;ldquo;在拥挤处耐心跟随&amp;rdquo;**而不仅仅是&amp;quot;避开人群&amp;rdquo;），或者更好地解读人类的行为意图。&lt;/p&gt;
&lt;h3&gt;2. 提升仿真环境的真实性&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;2-提升仿真环境的真实性&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#2-%e6%8f%90%e5%8d%87%e4%bb%bf%e7%9c%9f%e7%8e%af%e5%a2%83%e7%9a%84%e7%9c%9f%e5%ae%9e%e6%80%a7&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;开发更先进的仿真平台（如持续更新的 &lt;strong&gt;Arena 系列&lt;/strong&gt;），模拟更复杂的人类行为（如&lt;strong&gt;突然驻足、群体交谈、协作避让&lt;/strong&gt;），这对于在低成本前提下验证算法的鲁棒性至关重要。&lt;/p&gt;
&lt;h3&gt;3. 增强算法的可解释性与信任度&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;3-增强算法的可解释性与信任度&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#3-%e5%a2%9e%e5%bc%ba%e7%ae%97%e6%b3%95%e7%9a%84%e5%8f%af%e8%a7%a3%e9%87%8a%e6%80%a7%e4%b8%8e%e4%bf%a1%e4%bb%bb%e5%ba%a6&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;研究如何让机器人的导航决策过程对人类而言&lt;strong&gt;更透明、更容易理解&lt;/strong&gt;。例如，生成机器人为何选择某条路径的**&amp;ldquo;因果解释&amp;rdquo;**，这能极大地增强人类对机器人的信任，促进人机共处。&lt;/p&gt;
&lt;h3&gt;4. 深化人机交互研究&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;4-深化人机交互研究&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#4-%e6%b7%b1%e5%8c%96%e4%ba%ba%e6%9c%ba%e4%ba%a4%e4%ba%92%e7%a0%94%e7%a9%b6&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;关注机器人的导航行为如何影响人类的感受和效率。通过用户研究，量化什么是让人感到**&amp;ldquo;舒适&amp;rdquo;、&amp;ldquo;自然&amp;rdquo;**的机器人行为，并将这些发现转化为算法设计的指导原则。&lt;/p&gt;
&lt;h3&gt;5. 应对极端与复杂场景&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;5-应对极端与复杂场景&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#5-%e5%ba%94%e5%af%b9%e6%9e%81%e7%ab%af%e4%b8%8e%e5%a4%8d%e6%9d%82%e5%9c%ba%e6%99%af&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;专注于解决更具挑战性的场景，例如&lt;strong&gt;重度遮挡&lt;/strong&gt;（在人群中&amp;quot;看不见&amp;quot;部分行人）、对**&amp;ldquo;不可预测&amp;quot;行人的识别与避让**，以及在密集人群中如何寻找安全路径。&lt;/p&gt;
&lt;h3&gt;研究方向与未来工作规划&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;研究方向与未来工作规划&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#%e7%a0%94%e7%a9%b6%e6%96%b9%e5%90%91%e4%b8%8e%e6%9c%aa%e6%9d%a5%e5%b7%a5%e4%bd%9c%e8%a7%84%e5%88%92&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;基于 &lt;a href=&#34;https://github.com/Shuijing725/awesome-robot-social-navigation&#34;target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Awesome Robot Social Navigation&lt;/a&gt; 的梳理，当前研究主要集中在以下几个方向：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;研究方向&lt;/th&gt;
          &lt;th&gt;具体未来工作规划&lt;/th&gt;
          &lt;th&gt;来源论文&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&amp;lt;span style={{color: &amp;lsquo;red&amp;rsquo;}}&amp;gt;&lt;strong&gt;模型泛化与适应性&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
          &lt;td&gt;开发轻量化VLM便于机器人部署；探索&amp;lt;span style={{color: &amp;lsquo;red&amp;rsquo;}}&amp;gt;&lt;strong&gt;多模态融合（视觉、语言、传感器）&lt;/strong&gt;&lt;/span&gt;；研究&amp;lt;span style={{color: &amp;lsquo;red&amp;rsquo;}}&amp;gt;&lt;strong&gt;在线/终身学习框架以适应新场景&lt;/strong&gt;&lt;/span&gt;；提升对&amp;lt;span style={{color: &amp;lsquo;red&amp;rsquo;}}&amp;gt;&lt;strong&gt;动态场景和长时序任务的理解与规划能力&lt;/strong&gt;&lt;/span&gt;。&lt;/td&gt;
          &lt;td&gt;VLM-Social-Nav, OLiVia-Nav, Following the Human Thread&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&amp;lt;span style={{color: &amp;lsquo;red&amp;rsquo;}}&amp;gt;&lt;strong&gt;场景理解与交互&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
          &lt;td&gt;研究人类轨迹预测与社交动态的&amp;lt;span style={{color: &amp;lsquo;red&amp;rsquo;}}&amp;gt;&lt;strong&gt;实时、精准推断&lt;/strong&gt;&lt;/span&gt;；探索&amp;lt;span style={{color: &amp;lsquo;red&amp;rsquo;}}&amp;gt;&lt;strong&gt;多智能体协同与群体行为建模&lt;/strong&gt;&lt;/span&gt;；开发更强大的&amp;lt;span style={{color: &amp;lsquo;red&amp;rsquo;}}&amp;gt;&lt;strong&gt;场景表征与上下文理解能力&lt;/strong&gt;&lt;/span&gt;，以处理复杂的社会规则。&lt;/td&gt;
          &lt;td&gt;Following the Human Thread, DiPCAN&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;评估体系与伦理&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;建立更全面的评估指标（如引入&amp;quot;人类赋权&amp;quot;概念）；设计标准化基准测试与仿真环境；关注算法的公平性、透明度、隐私保护及人类舒适度等社会伦理影响。&lt;/td&gt;
          &lt;td&gt;In Search of a Lost Metric, Frontiers Research Topic&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;注：&lt;/strong&gt; benchmark一般貌似都要自己提出一个，这样能增大工作量说是，像TrackVLA就是这样提出了一个EVTbench开源使用&lt;/p&gt;

&lt;/blockquote&gt;
&lt;h3&gt;基于Awesome系列的具体研究方向&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;基于awesome系列的具体研究方向&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#%e5%9f%ba%e4%ba%8eawesome%e7%b3%bb%e5%88%97%e7%9a%84%e5%85%b7%e4%bd%93%e7%a0%94%e7%a9%b6%e6%96%b9%e5%90%91&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;根据&lt;a href=&#34;https://github.com/Shuijing725/awesome-robot-social-navigation&#34;target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Awesome系列&lt;/a&gt;的详细梳理，以下是从&lt;strong&gt;方法、数据集、评估&lt;/strong&gt;等多个维度总结的具体研究方向：&lt;/p&gt;
&lt;h4&gt;1. 基础模型在社交导航中的应用&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;1-基础模型在社交导航中的应用&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#1-%e5%9f%ba%e7%a1%80%e6%a8%a1%e5%9e%8b%e5%9c%a8%e7%a4%be%e4%ba%a4%e5%af%bc%e8%88%aa%e4%b8%ad%e7%9a%84%e5%ba%94%e7%94%a8&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;相关论文：&lt;/strong&gt; VLM-Social-Nav, OLiVia-Nav, Social-LLaVA, CoNVOI, BehAV&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;轻量化部署：&lt;/strong&gt; 研究如何将大型**视觉语言模型（VLM）&lt;strong&gt;和&lt;/strong&gt;大语言模型（LLM）**蒸馏或微调到适合机器人实时部署的规模&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多模态融合：&lt;/strong&gt; 探索视觉、语言、传感器数据的深度融合，提升对复杂社交场景的理解&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在线终身学习：&lt;/strong&gt; 开发能够持续适应新场景和人类行为的在线学习框架&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2. 轨迹预测与场景理解&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;2-轨迹预测与场景理解&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#2-%e8%bd%a8%e8%bf%b9%e9%a2%84%e6%b5%8b%e4%b8%8e%e5%9c%ba%e6%99%af%e7%90%86%e8%a7%a3&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;相关论文：&lt;/strong&gt; Social LSTM, STGAT, From Cognition to Precognition, Following the Human Thread&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;实时轨迹预测：&lt;/strong&gt; 提升对人类未来移动路径的预测精度和实时性&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;群体行为建模：&lt;/strong&gt; 研究多智能体协同、群体动态（如群体分裂与合并）的建模方法&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;上下文理解：&lt;/strong&gt; 开发更强大的场景表征能力，理解复杂的社会规则和社交动态&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;3. 强化学习与混合方法&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;3-强化学习与混合方法&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#3-%e5%bc%ba%e5%8c%96%e5%ad%a6%e4%b9%a0%e4%b8%8e%e6%b7%b7%e5%90%88%e6%96%b9%e6%b3%95&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;相关论文：&lt;/strong&gt; SACSoN, SELFI, DR-MPC, Hybrid Approaches&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;奖励函数设计：&lt;/strong&gt; 探索如何将社交规范、舒适度等抽象概念量化为强化学习的奖励信号&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;混合方法：&lt;/strong&gt; 结合模型预测控制（MPC）、采样规划等传统方法与深度强化学习&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;样本效率：&lt;/strong&gt; 提升强化学习在社交导航任务中的样本效率，减少真实世界训练成本&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;4. 可解释性与信任&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;4-可解释性与信任&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#4-%e5%8f%af%e8%a7%a3%e9%87%8a%e6%80%a7%e4%b8%8e%e4%bf%a1%e4%bb%bb&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;相关论文：&lt;/strong&gt; Generating Causal Explanations, Explainability and Trust&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;因果解释：&lt;/strong&gt; 生成机器人导航决策的因果解释，增强人类对机器人的信任&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;透明度：&lt;/strong&gt; 研究如何让机器人的决策过程对人类更透明、更容易理解&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;5. 数据集与评估基准&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;5-数据集与评估基准&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#5-%e6%95%b0%e6%8d%ae%e9%9b%86%e4%b8%8e%e8%af%84%e4%bc%b0%e5%9f%ba%e5%87%86&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;相关论文：&lt;/strong&gt; SCAND, MuSoHu, SocNavBench, Arena系列, SocialNav-SUB&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;真实世界数据集：&lt;/strong&gt; 构建大规模、多模态的真实人机交互数据集&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;仿真平台：&lt;/strong&gt; 开发更真实的仿真环境（如Arena 4.0, Habitat 3.0），支持复杂人类行为模拟&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估指标：&lt;/strong&gt; 设计更全面的评估体系，包括&lt;strong&gt;人类赋权&lt;/strong&gt;、个人空间合规性（PSC）、碰撞率（H-Coll）等&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;6. 用户研究与伦理&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;6-用户研究与伦理&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#6-%e7%94%a8%e6%88%b7%e7%a0%94%e7%a9%b6%e4%b8%8e%e4%bc%a6%e7%90%86&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;相关论文：&lt;/strong&gt; Social Momentum, How Do Robot Experts Measure Success, Overlapping Social Navigation Principles&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;用户研究：&lt;/strong&gt; 通过用户研究量化什么是&amp;quot;舒适&amp;rdquo;、&amp;ldquo;自然&amp;quot;的机器人行为&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;伦理考量：&lt;/strong&gt; 关注算法的公平性、透明度、隐私保护及对人类舒适度的影响&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;研究计划建议&lt;span class=&#34;hx:absolute hx:-mt-20&#34; id=&#34;研究计划建议&#34;&gt;&lt;/span&gt;
    &lt;a href=&#34;#%e7%a0%94%e7%a9%b6%e8%ae%a1%e5%88%92%e5%bb%ba%e8%ae%ae&#34; class=&#34;subheading-anchor&#34; aria-label=&#34;Permalink for this section&#34;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;基于以上分析，可以从以下几个方面思考研究计划：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;关注新兴的评估范式：&lt;/strong&gt; 像&lt;a href=&#34;http://export.arxiv.org/abs/2501.01539&#34;target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;人类赋权&amp;rdquo;&lt;/a&gt;这类新指标方兴未艾，如何量化、验证并将其有效融入强化学习奖励函数或模型预测控制的代价函数中，是一个很有潜力的方向。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;探索基础模型的高效应用：&lt;/strong&gt; 研究如何蒸馏或微调大型VLM/LMM，在保持其社交推理能力的同时，满足机器人平台对低延迟和低功耗的严苛要求。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;致力于弥合仿真与现实差距：&lt;/strong&gt; 开发更好的**领域自适应（Domain Adaptation）&lt;strong&gt;技术或&lt;/strong&gt;元学习（Meta-Learning）**策略，让模型在离开仿真环境后能快速适应真实世界的复杂性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;挑战更复杂的社交场景：&lt;/strong&gt; 可以专注于研究机器人在密集人群、群组交互（如穿越一个正在交谈的群体）或长程、多目标导航任务中的表现，这些场景对现有技术提出了更高要求。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;构建自己的评估基准：&lt;/strong&gt; 参考TrackVLA提出EVTbench的做法，开发针对特定场景或问题的标准化评估基准，这不仅能增加研究工作量，还能为领域提供有价值的工具。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
  </channel>
</rss>
